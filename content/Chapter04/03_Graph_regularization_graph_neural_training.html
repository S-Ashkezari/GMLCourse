
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Neural Graph Learning and Graph Regularization &#8212; Graph Machine Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/Chapter04/03_Graph_regularization_graph_neural_training';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Shallow methods for supervised learning" href="04_Graph_Neural_Networks.html" />
    <link rel="prev" title="Utility graph plot matrix" href="02_Shallow_embeddings.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="Graph Machine Learning - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="Graph Machine Learning - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Welcome to Graph Machhine Learning Workshop
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Chapter00/chap01_intro_and_basics.html">Introduction to Graphs and Machine Learning</a></li>

<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter01/01_Introduction_Networkx.html">Chapter 1 : Introduction to Networkx</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter01/02_Graph_metrics.html">Chapter 1.2: Graph properties</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter01/03_Graphs_Benchmarks.html">Benchmark and Repositories</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../Chapter02/01_embedding_examples.html">Chapter 2 : Embedding Examples</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter03/00_Unsupervised_Learning.html">Chapter 3 : Unsupervised machine learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter03/01_Shallow_Embeddings.html">Shallow embedding methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter03/02_Autoencoders.html">AutoEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter03/03_Structural_deep_neural_embeddings.html">Structural Deep Network Embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter03/04_Graph_Neural_Network.html">Unsupervised graph representation learning using Graph ConvNet</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="01_Feature_based_methods.html">Chapter 4 : Supervised Graph Learning</a></li>

<li class="toctree-l1"><a class="reference internal" href="../Chapter05/01_link_prediction.html">Chapter 5: Problems with Machine Learning on Graphs</a></li>

<li class="toctree-l1"><a class="reference internal" href="../Chapter06/01_Social_network_analysis.html">Chapter 6 : Machine learning on Social Netowrk Graphs</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/executablebooks/jupyter-book/blob/master/docs/content/Chapter04/03_Graph_regularization_graph_neural_training.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fcontent/Chapter04/03_Graph_regularization_graph_neural_training.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/content/Chapter04/03_Graph_regularization_graph_neural_training.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Neural Graph Learning and Graph Regularization</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-dataset">Load Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-the-model">Creating the model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vanilla-model">Vanilla Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-regularized-version">Graph Regularized Version</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="neural-graph-learning-and-graph-regularization">
<h1>Neural Graph Learning and Graph Regularization<a class="headerlink" href="#neural-graph-learning-and-graph-regularization" title="Link to this heading">#</a></h1>
<p>In this tutorial, we will be creating a graph regularized version for a topic classification task. The task is to classify paper depending on their content. However in order to do so, we will also use the information encoded in the citation network that relates documents among each other. Of course, we do know that this kind of information is indeed powerful as papers belonging to the same subject tend to reference each other.</p>
<section id="load-dataset">
<h2>Load Dataset<a class="headerlink" href="#load-dataset" title="Link to this heading">#</a></h2>
<p>For this tutorial we will be using the Cora dataset available in the stellargraph library</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">stellargraph</span><span class="w"> </span><span class="kn">import</span> <span class="n">datasets</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">from</span><span class="w"> </span><span class="nn">stellargraph</span><span class="w"> </span><span class="kn">import</span> <span class="n">datasets</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;stellargraph&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">Cora</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">config</span> Completer.use_jedi = False
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="o">.</span><span class="n">download</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">label_index</span> <span class="o">=</span> <span class="p">{</span>
      <span class="s1">&#39;Case_Based&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
      <span class="s1">&#39;Genetic_Algorithms&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
      <span class="s1">&#39;Neural_Networks&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
      <span class="s1">&#39;Probabilistic_Methods&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
      <span class="s1">&#39;Reinforcement_Learning&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
      <span class="s1">&#39;Rule_Learning&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
      <span class="s1">&#39;Theory&#39;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>
  <span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">G</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We now create the Dataset object where we will both include information of the targeted sample (node) and its neighbors. In the following we will also allow to control the number of labelling instances to be used, in order to reproduce and evaluate the classification performance in a semi-supervised setting.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn</span><span class="w"> </span><span class="kn">import</span> <span class="n">preprocessing</span><span class="p">,</span> <span class="n">feature_extraction</span><span class="p">,</span> <span class="n">model_selection</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.train</span><span class="w"> </span><span class="kn">import</span> <span class="n">Example</span><span class="p">,</span> <span class="n">Features</span><span class="p">,</span> <span class="n">Feature</span><span class="p">,</span> <span class="n">Int64List</span><span class="p">,</span> <span class="n">BytesList</span><span class="p">,</span> <span class="n">FloatList</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">GRAPH_PREFIX</span><span class="o">=</span><span class="s2">&quot;NL_nbr&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">_int64_feature</span><span class="p">(</span><span class="o">*</span><span class="n">value</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns int64 tf.train.Feature from a bool / enum / int / uint.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Feature</span><span class="p">(</span><span class="n">int64_list</span><span class="o">=</span><span class="n">Int64List</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">value</span><span class="p">)))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_bytes_feature</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns bytes tf.train.Feature from a string.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Feature</span><span class="p">(</span>
        <span class="n">bytes_list</span><span class="o">=</span><span class="n">BytesList</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="p">[</span><span class="n">value</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)])</span>
    <span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_float_feature</span><span class="p">(</span><span class="o">*</span><span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">Feature</span><span class="p">(</span><span class="n">float_list</span><span class="o">=</span><span class="n">FloatList</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">value</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">reduce</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">six</span>

<span class="k">def</span><span class="w"> </span><span class="nf">addFeatures</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">Features</span><span class="p">()</span>
    <span class="n">res</span><span class="o">.</span><span class="n">CopyFrom</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">res</span><span class="o">.</span><span class="n">MergeFrom</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span>

<span class="k">def</span><span class="w"> </span><span class="nf">neighborFeatures</span><span class="p">(</span><span class="n">features</span><span class="p">:</span> <span class="n">Features</span><span class="p">,</span> <span class="n">weight</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_weight&quot;</span><span class="p">:</span> <span class="n">_float_feature</span><span class="p">(</span><span class="n">weight</span><span class="p">)}</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">iteritems</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">feature</span><span class="p">):</span>
        <span class="n">data</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">feature</span> 
    <span class="k">return</span> <span class="n">Features</span><span class="p">(</span><span class="n">feature</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">neighborsFeatures</span><span class="p">(</span><span class="n">neighbors</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Features</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]):</span>
    <span class="k">return</span> <span class="n">reduce</span><span class="p">(</span>
        <span class="n">addFeatures</span><span class="p">,</span> 
        <span class="p">[</span><span class="n">neighborFeatures</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">GRAPH_PREFIX</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">ith</span><span class="p">,</span> <span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">neighbors</span><span class="p">)],</span>
        <span class="n">Features</span><span class="p">()</span>
    <span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">getNeighbors</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">adjMatrix</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">adjMatrix</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">weights</span><span class="p">[</span><span class="n">weights</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">topn</span><span class="p">)</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
    

<span class="k">def</span><span class="w"> </span><span class="nf">semisupervisedDataset</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span><span class="o">*</span><span class="n">ratio</span><span class="p">))</span>
    
    <span class="n">labelled</span><span class="p">,</span> <span class="n">unlabelled</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span>
        <span class="n">labels</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">labels</span>
    <span class="p">)</span>
    
    <span class="n">adjMatrix</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">from_spmatrix</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">to_adjacency_matrix</span><span class="p">(),</span> <span class="n">index</span><span class="o">=</span><span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>
    
    <span class="n">features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">node_features</span><span class="p">(),</span> <span class="n">index</span><span class="o">=</span><span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>
    
    <span class="n">dataset</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">index</span><span class="p">:</span> <span class="n">Features</span><span class="p">(</span><span class="n">feature</span> <span class="o">=</span> <span class="p">{</span>
            <span class="c1">#&quot;id&quot;: _bytes_feature(str(index)), </span>
            <span class="s2">&quot;id&quot;</span><span class="p">:</span> <span class="n">_int64_feature</span><span class="p">(</span><span class="n">index</span><span class="p">),</span>
            <span class="s2">&quot;words&quot;</span><span class="p">:</span> <span class="n">_float_feature</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">features</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">]),</span> 
            <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="n">_int64_feature</span><span class="p">(</span><span class="n">label_index</span><span class="p">[</span><span class="n">label</span><span class="p">])</span>
        <span class="p">})</span>
        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">labelled</span><span class="p">,</span> <span class="n">unlabelled</span><span class="p">])</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
    <span class="p">}</span>
    
    <span class="n">trainingSet</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">Example</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">addFeatures</span><span class="p">(</span>
            <span class="n">dataset</span><span class="p">[</span><span class="n">exampleId</span><span class="p">],</span> 
            <span class="n">neighborsFeatures</span><span class="p">(</span>
                <span class="p">[(</span><span class="n">dataset</span><span class="p">[</span><span class="n">nodeId</span><span class="p">],</span> <span class="n">weight</span><span class="p">)</span> <span class="k">for</span> <span class="n">nodeId</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">getNeighbors</span><span class="p">(</span><span class="n">exampleId</span><span class="p">,</span> <span class="n">adjMatrix</span><span class="p">,</span> <span class="n">topn</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>
            <span class="p">)</span>
        <span class="p">))</span>
        <span class="k">for</span> <span class="n">exampleId</span> <span class="ow">in</span> <span class="n">labelled</span><span class="o">.</span><span class="n">index</span>
    <span class="p">]</span>
    
    <span class="n">testSet</span> <span class="o">=</span> <span class="p">[</span><span class="n">Example</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="n">exampleId</span><span class="p">])</span> <span class="k">for</span> <span class="n">exampleId</span> <span class="ow">in</span> <span class="n">unlabelled</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>

    <span class="n">serializer</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">_list</span><span class="p">:</span> <span class="p">[</span><span class="n">e</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">()</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">_list</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">serializer</span><span class="p">(</span><span class="n">trainingSet</span><span class="p">),</span> <span class="n">serializer</span><span class="p">(</span><span class="n">testSet</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We split the dataset into a training set and a test set</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainingSet</span><span class="p">,</span> <span class="n">testSet</span> <span class="o">=</span> <span class="n">semisupervisedDataset</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vocabularySize</span> <span class="o">=</span> <span class="mi">1433</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">neighbors</span><span class="o">=</span><span class="mi">2</span>
<span class="n">defaultWord</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">vocabularySize</span><span class="p">])</span>

<span class="k">def</span><span class="w"> </span><span class="nf">parseExample</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">schema</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;words&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">FixedLenFeature</span><span class="p">([</span><span class="n">vocabularySize</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">default_value</span><span class="o">=</span><span class="n">defaultWord</span><span class="p">),</span>
        <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">FixedLenFeature</span><span class="p">((),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">default_value</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="p">}</span>
    
    <span class="k">if</span> <span class="n">training</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">neighbors</span><span class="p">):</span>
            <span class="n">name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">GRAPH_PREFIX</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">schema</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_weight&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">FixedLenFeature</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">default_value</span><span class="o">=</span><span class="p">[</span><span class="mf">0.0</span><span class="p">])</span>
            <span class="n">schema</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_words&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">FixedLenFeature</span><span class="p">([</span><span class="n">vocabularySize</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">default_value</span><span class="o">=</span><span class="n">defaultWord</span><span class="p">)</span>
    
    <span class="n">features</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">parse_single_example</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">schema</span><span class="p">)</span>
    
    <span class="n">label</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;label&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">features</span><span class="p">,</span> <span class="n">label</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">sampleGenerator</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">wrapper</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">example</span>
    <span class="k">return</span> <span class="n">wrapper</span>
            
<span class="n">myTrain</span> <span class="o">=</span> <span class="n">Dataset</span> \
    <span class="o">.</span><span class="n">from_generator</span><span class="p">(</span><span class="n">sampleGenerator</span><span class="p">(</span><span class="n">trainingSet</span><span class="p">),</span> <span class="n">output_types</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">,</span> <span class="n">output_shapes</span><span class="o">=</span><span class="p">())</span> \
    <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">parseExample</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="kc">True</span><span class="p">))</span>

<span class="n">myTest</span> <span class="o">=</span> <span class="n">Dataset</span> \
    <span class="o">.</span><span class="n">from_generator</span><span class="p">(</span><span class="n">sampleGenerator</span><span class="p">(</span><span class="n">testSet</span><span class="p">),</span> <span class="n">output_types</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">,</span> <span class="n">output_shapes</span><span class="o">=</span><span class="p">())</span> \
    <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">parseExample</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">myTrain</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;NL_nbr_0_weight&#39;: &lt;tf.Tensor: shape=(10, 1), dtype=float32, numpy=
array([[2.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [2.],
       [1.],
       [1.]], dtype=float32)&gt;, &#39;NL_nbr_0_words&#39;: &lt;tf.Tensor: shape=(10, 1433), dtype=float32, numpy=
array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 1., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)&gt;, &#39;NL_nbr_1_weight&#39;: &lt;tf.Tensor: shape=(10, 1), dtype=float32, numpy=
array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]], dtype=float32)&gt;, &#39;NL_nbr_1_words&#39;: &lt;tf.Tensor: shape=(10, 1433), dtype=float32, numpy=
array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)&gt;, &#39;words&#39;: &lt;tf.Tensor: shape=(10, 1433), dtype=float32, numpy=
array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)&gt;}
tf.Tensor([1 1 4 1 0 5 2 1 6 3], shape=(10,), dtype=int64)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">myTest</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;words&#39;: &lt;tf.Tensor: shape=(10, 1433), dtype=float32, numpy=
array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)&gt;}
tf.Tensor([1 1 3 3 2 4 5 3 2 6], shape=(10,), dtype=int64)
</pre></div>
</div>
</div>
</div>
</section>
<section id="creating-the-model">
<h2>Creating the model<a class="headerlink" href="#creating-the-model" title="Link to this heading">#</a></h2>
<p>We now create the model that we will use to classify the documents</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;Creates a functional API-based multi-layer perceptron model.&quot;&quot;&quot;</span>
<span class="k">def</span><span class="w"> </span><span class="nf">create_model</span><span class="p">(</span><span class="n">num_units</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span>
          <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">vocabularySize</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;words&#39;</span>
    <span class="p">)</span>

    <span class="c1"># outputs = tf.keras.layers.Dense(len(label_index), activation=&#39;softmax&#39;)(inputs)</span>

    <span class="n">cur_layer</span> <span class="o">=</span>  <span class="n">inputs</span>

    <span class="k">for</span> <span class="n">num_units</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">:</span>
        <span class="n">cur_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">cur_layer</span><span class="p">)</span>
        <span class="n">cur_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.8</span><span class="p">)(</span><span class="n">cur_layer</span><span class="p">)</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">label_index</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)(</span><span class="n">cur_layer</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.callbacks</span><span class="w"> </span><span class="kn">import</span> <span class="n">TensorBoard</span>
</pre></div>
</div>
</div>
</div>
<section id="vanilla-model">
<h3>Vanilla Model<a class="headerlink" href="#vanilla-model" title="Link to this heading">#</a></h3>
<p>We first train a simple, vanilla version that does not use the citation network information</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">([</span><span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;model&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
words (InputLayer)           [(None, 1433)]            0         
_________________________________________________________________
dense (Dense)                (None, 50)                71700     
_________________________________________________________________
dropout (Dropout)            (None, 50)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 50)                2550      
_________________________________________________________________
dropout_1 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 7)                 357       
=================================================================
Total params: 74,607
Trainable params: 74,607
Non-trainable params: 0
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">myTrain</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="n">myTest</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span>
          <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">TensorBoard</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s1">&#39;/tmp/noRegularization&#39;</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/200
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/deusebio/.pyenv/versions/3.7.6/envs/ml-book-4/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys [&#39;NL_nbr_0_weight&#39;, &#39;NL_nbr_0_words&#39;, &#39;NL_nbr_1_weight&#39;, &#39;NL_nbr_1_words&#39;] which did not match any model input. They will be ignored by the model.
  [n for n in tensors.keys() if n not in ref_input_names])
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5/5 [==============================] - 2s 323ms/step - loss: 1.9820 - accuracy: 0.1390 - val_loss: 1.9311 - val_accuracy: 0.2022
Epoch 2/200
5/5 [==============================] - 0s 114ms/step - loss: 1.9699 - accuracy: 0.1779 - val_loss: 1.9219 - val_accuracy: 0.2373
Epoch 3/200
5/5 [==============================] - 0s 117ms/step - loss: 1.9632 - accuracy: 0.1964 - val_loss: 1.9135 - val_accuracy: 0.2742
Epoch 4/200
5/5 [==============================] - 0s 106ms/step - loss: 2.0003 - accuracy: 0.1981 - val_loss: 1.9071 - val_accuracy: 0.2886
Epoch 5/200
5/5 [==============================] - 1s 117ms/step - loss: 1.9681 - accuracy: 0.1810 - val_loss: 1.9010 - val_accuracy: 0.2941
Epoch 6/200
5/5 [==============================] - 0s 117ms/step - loss: 1.8860 - accuracy: 0.2400 - val_loss: 1.8951 - val_accuracy: 0.3010
Epoch 7/200
5/5 [==============================] - 1s 124ms/step - loss: 1.8809 - accuracy: 0.2603 - val_loss: 1.8888 - val_accuracy: 0.3052
Epoch 8/200
5/5 [==============================] - 0s 111ms/step - loss: 1.8710 - accuracy: 0.2564 - val_loss: 1.8819 - val_accuracy: 0.3038
Epoch 9/200
5/5 [==============================] - 1s 130ms/step - loss: 1.8745 - accuracy: 0.2519 - val_loss: 1.8754 - val_accuracy: 0.3015
Epoch 10/200
5/5 [==============================] - 0s 111ms/step - loss: 1.8847 - accuracy: 0.2621 - val_loss: 1.8691 - val_accuracy: 0.3024
Epoch 11/200
5/5 [==============================] - 1s 117ms/step - loss: 1.8810 - accuracy: 0.2581 - val_loss: 1.8633 - val_accuracy: 0.3029
Epoch 12/200
5/5 [==============================] - 1s 124ms/step - loss: 1.8815 - accuracy: 0.2402 - val_loss: 1.8580 - val_accuracy: 0.3024
Epoch 13/200
5/5 [==============================] - 0s 109ms/step - loss: 1.8592 - accuracy: 0.2660 - val_loss: 1.8530 - val_accuracy: 0.3024
Epoch 14/200
5/5 [==============================] - 0s 106ms/step - loss: 1.8818 - accuracy: 0.2764 - val_loss: 1.8481 - val_accuracy: 0.3024
Epoch 15/200
5/5 [==============================] - 0s 112ms/step - loss: 1.8602 - accuracy: 0.2645 - val_loss: 1.8436 - val_accuracy: 0.3029
Epoch 16/200
5/5 [==============================] - 0s 110ms/step - loss: 1.8200 - accuracy: 0.2913 - val_loss: 1.8386 - val_accuracy: 0.3024
Epoch 17/200
5/5 [==============================] - 0s 105ms/step - loss: 1.7878 - accuracy: 0.2694 - val_loss: 1.8328 - val_accuracy: 0.3024
Epoch 18/200
5/5 [==============================] - 0s 104ms/step - loss: 1.8208 - accuracy: 0.2823 - val_loss: 1.8262 - val_accuracy: 0.3019
Epoch 19/200
5/5 [==============================] - 0s 116ms/step - loss: 1.8273 - accuracy: 0.2808 - val_loss: 1.8200 - val_accuracy: 0.3019
Epoch 20/200
5/5 [==============================] - 1s 122ms/step - loss: 1.8076 - accuracy: 0.2861 - val_loss: 1.8137 - val_accuracy: 0.3019
Epoch 21/200
5/5 [==============================] - 0s 112ms/step - loss: 1.7817 - accuracy: 0.2773 - val_loss: 1.8071 - val_accuracy: 0.3019
Epoch 22/200
5/5 [==============================] - 1s 148ms/step - loss: 1.7817 - accuracy: 0.2879 - val_loss: 1.7996 - val_accuracy: 0.3019
Epoch 23/200
5/5 [==============================] - 0s 106ms/step - loss: 1.8022 - accuracy: 0.2694 - val_loss: 1.7920 - val_accuracy: 0.3019
Epoch 24/200
5/5 [==============================] - 0s 113ms/step - loss: 1.7664 - accuracy: 0.2857 - val_loss: 1.7837 - val_accuracy: 0.3019
Epoch 25/200
5/5 [==============================] - 1s 118ms/step - loss: 1.7413 - accuracy: 0.3139 - val_loss: 1.7750 - val_accuracy: 0.3019
Epoch 26/200
5/5 [==============================] - 0s 111ms/step - loss: 1.7423 - accuracy: 0.2957 - val_loss: 1.7673 - val_accuracy: 0.3019
Epoch 27/200
5/5 [==============================] - 0s 104ms/step - loss: 1.7182 - accuracy: 0.3222 - val_loss: 1.7600 - val_accuracy: 0.3019
Epoch 28/200
5/5 [==============================] - 0s 109ms/step - loss: 1.7282 - accuracy: 0.3140 - val_loss: 1.7521 - val_accuracy: 0.3019
Epoch 29/200
5/5 [==============================] - 1s 132ms/step - loss: 1.7342 - accuracy: 0.2928 - val_loss: 1.7451 - val_accuracy: 0.3019
Epoch 30/200
5/5 [==============================] - 0s 116ms/step - loss: 1.6762 - accuracy: 0.3217 - val_loss: 1.7368 - val_accuracy: 0.3019
Epoch 31/200
5/5 [==============================] - 0s 106ms/step - loss: 1.7440 - accuracy: 0.2937 - val_loss: 1.7286 - val_accuracy: 0.3019
Epoch 32/200
5/5 [==============================] - 1s 119ms/step - loss: 1.7002 - accuracy: 0.2902 - val_loss: 1.7214 - val_accuracy: 0.3024
Epoch 33/200
5/5 [==============================] - 0s 106ms/step - loss: 1.6856 - accuracy: 0.3105 - val_loss: 1.7143 - val_accuracy: 0.3029
Epoch 34/200
5/5 [==============================] - 1s 120ms/step - loss: 1.6947 - accuracy: 0.2990 - val_loss: 1.7079 - val_accuracy: 0.3033
Epoch 35/200
5/5 [==============================] - 0s 107ms/step - loss: 1.6785 - accuracy: 0.3159 - val_loss: 1.7024 - val_accuracy: 0.3038
Epoch 36/200
5/5 [==============================] - 0s 117ms/step - loss: 1.6167 - accuracy: 0.3351 - val_loss: 1.6960 - val_accuracy: 0.3052
Epoch 37/200
5/5 [==============================] - 0s 114ms/step - loss: 1.6379 - accuracy: 0.3163 - val_loss: 1.6889 - val_accuracy: 0.3056
Epoch 38/200
5/5 [==============================] - 0s 117ms/step - loss: 1.6286 - accuracy: 0.3426 - val_loss: 1.6814 - val_accuracy: 0.3066
Epoch 39/200
5/5 [==============================] - 1s 118ms/step - loss: 1.6328 - accuracy: 0.3559 - val_loss: 1.6738 - val_accuracy: 0.3084
Epoch 40/200
5/5 [==============================] - 1s 118ms/step - loss: 1.6194 - accuracy: 0.3266 - val_loss: 1.6667 - val_accuracy: 0.3126
Epoch 41/200
5/5 [==============================] - 1s 117ms/step - loss: 1.5999 - accuracy: 0.3031 - val_loss: 1.6612 - val_accuracy: 0.3181
Epoch 42/200
5/5 [==============================] - 0s 111ms/step - loss: 1.6033 - accuracy: 0.3178 - val_loss: 1.6555 - val_accuracy: 0.3246
Epoch 43/200
5/5 [==============================] - 0s 111ms/step - loss: 1.6016 - accuracy: 0.3283 - val_loss: 1.6490 - val_accuracy: 0.3338
Epoch 44/200
5/5 [==============================] - 0s 107ms/step - loss: 1.5466 - accuracy: 0.3435 - val_loss: 1.6403 - val_accuracy: 0.3430
Epoch 45/200
5/5 [==============================] - 0s 107ms/step - loss: 1.5700 - accuracy: 0.3411 - val_loss: 1.6300 - val_accuracy: 0.3500
Epoch 46/200
5/5 [==============================] - 1s 152ms/step - loss: 1.5677 - accuracy: 0.3146 - val_loss: 1.6208 - val_accuracy: 0.3587
Epoch 47/200
5/5 [==============================] - 1s 163ms/step - loss: 1.5848 - accuracy: 0.3527 - val_loss: 1.6121 - val_accuracy: 0.3652
Epoch 48/200
5/5 [==============================] - 1s 159ms/step - loss: 1.5458 - accuracy: 0.3726 - val_loss: 1.6040 - val_accuracy: 0.3703
Epoch 49/200
5/5 [==============================] - 1s 128ms/step - loss: 1.5457 - accuracy: 0.3176 - val_loss: 1.5965 - val_accuracy: 0.3758
Epoch 50/200
5/5 [==============================] - 1s 143ms/step - loss: 1.5226 - accuracy: 0.3776 - val_loss: 1.5889 - val_accuracy: 0.3804
Epoch 51/200
5/5 [==============================] - 0s 113ms/step - loss: 1.5445 - accuracy: 0.3343 - val_loss: 1.5813 - val_accuracy: 0.3869
Epoch 52/200
5/5 [==============================] - 1s 127ms/step - loss: 1.5416 - accuracy: 0.3672 - val_loss: 1.5740 - val_accuracy: 0.3938
Epoch 53/200
5/5 [==============================] - 0s 113ms/step - loss: 1.4925 - accuracy: 0.3735 - val_loss: 1.5666 - val_accuracy: 0.3984
Epoch 54/200
5/5 [==============================] - 1s 120ms/step - loss: 1.4956 - accuracy: 0.3615 - val_loss: 1.5591 - val_accuracy: 0.4035
Epoch 55/200
5/5 [==============================] - 0s 108ms/step - loss: 1.5306 - accuracy: 0.3399 - val_loss: 1.5520 - val_accuracy: 0.4090
Epoch 56/200
5/5 [==============================] - 0s 115ms/step - loss: 1.4512 - accuracy: 0.3820 - val_loss: 1.5445 - val_accuracy: 0.4155
Epoch 57/200
5/5 [==============================] - 1s 131ms/step - loss: 1.4307 - accuracy: 0.3891 - val_loss: 1.5374 - val_accuracy: 0.4183
Epoch 58/200
5/5 [==============================] - 1s 120ms/step - loss: 1.4430 - accuracy: 0.3657 - val_loss: 1.5300 - val_accuracy: 0.4247
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 59/200
5/5 [==============================] - 1s 143ms/step - loss: 1.4438 - accuracy: 0.3667 - val_loss: 1.5221 - val_accuracy: 0.4280
Epoch 60/200
5/5 [==============================] - 0s 112ms/step - loss: 1.4592 - accuracy: 0.3633 - val_loss: 1.5149 - val_accuracy: 0.4326
Epoch 61/200
5/5 [==============================] - 1s 182ms/step - loss: 1.4056 - accuracy: 0.3988 - val_loss: 1.5073 - val_accuracy: 0.4367
Epoch 62/200
5/5 [==============================] - 1s 125ms/step - loss: 1.4253 - accuracy: 0.3948 - val_loss: 1.5000 - val_accuracy: 0.4414
Epoch 63/200
5/5 [==============================] - 1s 149ms/step - loss: 1.3744 - accuracy: 0.4412 - val_loss: 1.4925 - val_accuracy: 0.4460
Epoch 64/200
5/5 [==============================] - 1s 133ms/step - loss: 1.3908 - accuracy: 0.4052 - val_loss: 1.4845 - val_accuracy: 0.4478
Epoch 65/200
5/5 [==============================] - 1s 119ms/step - loss: 1.3819 - accuracy: 0.4087 - val_loss: 1.4763 - val_accuracy: 0.4538
Epoch 66/200
5/5 [==============================] - 1s 130ms/step - loss: 1.3798 - accuracy: 0.4137 - val_loss: 1.4688 - val_accuracy: 0.4566
Epoch 67/200
5/5 [==============================] - 1s 125ms/step - loss: 1.3816 - accuracy: 0.4319 - val_loss: 1.4618 - val_accuracy: 0.4580
Epoch 68/200
5/5 [==============================] - 1s 122ms/step - loss: 1.3548 - accuracy: 0.4387 - val_loss: 1.4549 - val_accuracy: 0.4594
Epoch 69/200
5/5 [==============================] - 1s 144ms/step - loss: 1.3364 - accuracy: 0.4546 - val_loss: 1.4484 - val_accuracy: 0.4608
Epoch 70/200
5/5 [==============================] - 1s 137ms/step - loss: 1.3729 - accuracy: 0.4436 - val_loss: 1.4427 - val_accuracy: 0.4612
Epoch 71/200
5/5 [==============================] - 1s 142ms/step - loss: 1.3252 - accuracy: 0.4525 - val_loss: 1.4366 - val_accuracy: 0.4658
Epoch 72/200
5/5 [==============================] - 1s 125ms/step - loss: 1.3500 - accuracy: 0.4421 - val_loss: 1.4302 - val_accuracy: 0.4695
Epoch 73/200
5/5 [==============================] - 1s 121ms/step - loss: 1.2927 - accuracy: 0.4529 - val_loss: 1.4238 - val_accuracy: 0.4718
Epoch 74/200
5/5 [==============================] - 1s 129ms/step - loss: 1.2843 - accuracy: 0.4799 - val_loss: 1.4185 - val_accuracy: 0.4760
Epoch 75/200
5/5 [==============================] - 1s 140ms/step - loss: 1.2724 - accuracy: 0.5005 - val_loss: 1.4128 - val_accuracy: 0.4829
Epoch 76/200
5/5 [==============================] - 1s 119ms/step - loss: 1.3129 - accuracy: 0.4651 - val_loss: 1.4083 - val_accuracy: 0.4848
Epoch 77/200
5/5 [==============================] - 1s 121ms/step - loss: 1.2618 - accuracy: 0.4697 - val_loss: 1.4047 - val_accuracy: 0.4861
Epoch 78/200
5/5 [==============================] - 1s 140ms/step - loss: 1.2413 - accuracy: 0.5125 - val_loss: 1.4003 - val_accuracy: 0.4885
Epoch 79/200
5/5 [==============================] - 1s 118ms/step - loss: 1.2087 - accuracy: 0.5341 - val_loss: 1.3955 - val_accuracy: 0.4903
Epoch 80/200
5/5 [==============================] - 0s 117ms/step - loss: 1.2851 - accuracy: 0.4639 - val_loss: 1.3900 - val_accuracy: 0.4935
Epoch 81/200
5/5 [==============================] - 1s 155ms/step - loss: 1.2209 - accuracy: 0.5177 - val_loss: 1.3837 - val_accuracy: 0.4986
Epoch 82/200
5/5 [==============================] - 1s 165ms/step - loss: 1.1996 - accuracy: 0.5319 - val_loss: 1.3780 - val_accuracy: 0.5005
Epoch 83/200
5/5 [==============================] - 1s 136ms/step - loss: 1.2368 - accuracy: 0.4949 - val_loss: 1.3740 - val_accuracy: 0.5046
Epoch 84/200
5/5 [==============================] - 1s 128ms/step - loss: 1.2231 - accuracy: 0.5320 - val_loss: 1.3710 - val_accuracy: 0.5069
Epoch 85/200
5/5 [==============================] - 1s 124ms/step - loss: 1.2342 - accuracy: 0.5022 - val_loss: 1.3667 - val_accuracy: 0.5106
Epoch 86/200
5/5 [==============================] - 1s 121ms/step - loss: 1.2375 - accuracy: 0.4890 - val_loss: 1.3614 - val_accuracy: 0.5125
Epoch 87/200
5/5 [==============================] - 1s 126ms/step - loss: 1.2203 - accuracy: 0.5061 - val_loss: 1.3577 - val_accuracy: 0.5162
Epoch 88/200
5/5 [==============================] - 1s 120ms/step - loss: 1.2521 - accuracy: 0.5327 - val_loss: 1.3570 - val_accuracy: 0.5185
Epoch 89/200
5/5 [==============================] - 0s 117ms/step - loss: 1.1961 - accuracy: 0.5341 - val_loss: 1.3572 - val_accuracy: 0.5194
Epoch 90/200
5/5 [==============================] - 1s 123ms/step - loss: 1.1892 - accuracy: 0.5204 - val_loss: 1.3551 - val_accuracy: 0.5226
Epoch 91/200
5/5 [==============================] - 1s 137ms/step - loss: 1.1887 - accuracy: 0.5302 - val_loss: 1.3544 - val_accuracy: 0.5268
Epoch 92/200
5/5 [==============================] - 1s 125ms/step - loss: 1.1729 - accuracy: 0.5289 - val_loss: 1.3553 - val_accuracy: 0.5254
Epoch 93/200
5/5 [==============================] - 1s 129ms/step - loss: 1.1671 - accuracy: 0.5114 - val_loss: 1.3555 - val_accuracy: 0.5277
Epoch 94/200
5/5 [==============================] - 1s 121ms/step - loss: 1.1611 - accuracy: 0.5413 - val_loss: 1.3543 - val_accuracy: 0.5277
Epoch 95/200
5/5 [==============================] - 1s 156ms/step - loss: 1.1913 - accuracy: 0.5282 - val_loss: 1.3525 - val_accuracy: 0.5259
Epoch 96/200
5/5 [==============================] - 1s 168ms/step - loss: 1.1435 - accuracy: 0.5480 - val_loss: 1.3524 - val_accuracy: 0.5263
Epoch 97/200
5/5 [==============================] - 1s 130ms/step - loss: 1.1390 - accuracy: 0.5413 - val_loss: 1.3516 - val_accuracy: 0.5295
Epoch 98/200
5/5 [==============================] - 1s 120ms/step - loss: 1.1598 - accuracy: 0.5492 - val_loss: 1.3472 - val_accuracy: 0.5328
Epoch 99/200
5/5 [==============================] - 1s 122ms/step - loss: 1.1754 - accuracy: 0.4923 - val_loss: 1.3409 - val_accuracy: 0.5360
Epoch 100/200
5/5 [==============================] - 1s 126ms/step - loss: 1.1441 - accuracy: 0.5521 - val_loss: 1.3364 - val_accuracy: 0.5397
Epoch 101/200
5/5 [==============================] - 1s 140ms/step - loss: 1.1213 - accuracy: 0.5697 - val_loss: 1.3323 - val_accuracy: 0.5416
Epoch 102/200
5/5 [==============================] - 1s 125ms/step - loss: 1.1414 - accuracy: 0.5274 - val_loss: 1.3311 - val_accuracy: 0.5420
Epoch 103/200
5/5 [==============================] - 1s 151ms/step - loss: 1.0863 - accuracy: 0.5567 - val_loss: 1.3315 - val_accuracy: 0.5439
Epoch 104/200
5/5 [==============================] - 1s 132ms/step - loss: 1.0917 - accuracy: 0.5921 - val_loss: 1.3338 - val_accuracy: 0.5439
Epoch 105/200
5/5 [==============================] - 1s 130ms/step - loss: 1.1084 - accuracy: 0.5622 - val_loss: 1.3379 - val_accuracy: 0.5416
Epoch 106/200
5/5 [==============================] - 1s 130ms/step - loss: 1.0470 - accuracy: 0.5800 - val_loss: 1.3419 - val_accuracy: 0.5425
Epoch 107/200
5/5 [==============================] - 1s 124ms/step - loss: 1.0953 - accuracy: 0.5640 - val_loss: 1.3420 - val_accuracy: 0.5429
Epoch 108/200
5/5 [==============================] - 1s 133ms/step - loss: 1.0905 - accuracy: 0.5702 - val_loss: 1.3417 - val_accuracy: 0.5434
Epoch 109/200
5/5 [==============================] - 1s 140ms/step - loss: 1.1185 - accuracy: 0.5661 - val_loss: 1.3425 - val_accuracy: 0.5457
Epoch 110/200
5/5 [==============================] - 1s 129ms/step - loss: 1.0886 - accuracy: 0.5817 - val_loss: 1.3417 - val_accuracy: 0.5466
Epoch 111/200
5/5 [==============================] - 1s 132ms/step - loss: 1.0223 - accuracy: 0.6096 - val_loss: 1.3427 - val_accuracy: 0.5476
Epoch 112/200
5/5 [==============================] - 1s 130ms/step - loss: 1.0619 - accuracy: 0.5801 - val_loss: 1.3440 - val_accuracy: 0.5485
Epoch 113/200
5/5 [==============================] - 1s 125ms/step - loss: 1.0970 - accuracy: 0.5693 - val_loss: 1.3435 - val_accuracy: 0.5489
Epoch 114/200
5/5 [==============================] - 1s 122ms/step - loss: 1.0307 - accuracy: 0.5842 - val_loss: 1.3434 - val_accuracy: 0.5503
Epoch 115/200
5/5 [==============================] - 1s 128ms/step - loss: 1.0729 - accuracy: 0.5749 - val_loss: 1.3409 - val_accuracy: 0.5512
Epoch 116/200
5/5 [==============================] - 1s 132ms/step - loss: 1.0652 - accuracy: 0.5892 - val_loss: 1.3405 - val_accuracy: 0.5526
Epoch 117/200
5/5 [==============================] - 1s 146ms/step - loss: 1.0331 - accuracy: 0.5950 - val_loss: 1.3448 - val_accuracy: 0.5531
Epoch 118/200
5/5 [==============================] - 1s 137ms/step - loss: 1.0661 - accuracy: 0.6041 - val_loss: 1.3518 - val_accuracy: 0.5536
Epoch 119/200
5/5 [==============================] - 1s 127ms/step - loss: 1.0243 - accuracy: 0.6106 - val_loss: 1.3588 - val_accuracy: 0.5512
Epoch 120/200
5/5 [==============================] - 1s 129ms/step - loss: 0.9959 - accuracy: 0.6434 - val_loss: 1.3643 - val_accuracy: 0.5508
Epoch 121/200
5/5 [==============================] - 1s 127ms/step - loss: 1.0377 - accuracy: 0.6012 - val_loss: 1.3699 - val_accuracy: 0.5503
Epoch 122/200
5/5 [==============================] - 1s 129ms/step - loss: 1.0587 - accuracy: 0.5726 - val_loss: 1.3722 - val_accuracy: 0.5512
Epoch 123/200
5/5 [==============================] - 1s 137ms/step - loss: 1.0212 - accuracy: 0.5867 - val_loss: 1.3694 - val_accuracy: 0.5536
Epoch 124/200
5/5 [==============================] - 1s 189ms/step - loss: 1.0011 - accuracy: 0.6239 - val_loss: 1.3711 - val_accuracy: 0.5522
Epoch 125/200
5/5 [==============================] - 1s 141ms/step - loss: 0.9889 - accuracy: 0.6348 - val_loss: 1.3728 - val_accuracy: 0.5536
Epoch 126/200
5/5 [==============================] - 1s 181ms/step - loss: 1.0428 - accuracy: 0.5786 - val_loss: 1.3751 - val_accuracy: 0.5522
Epoch 127/200
5/5 [==============================] - 1s 135ms/step - loss: 0.9908 - accuracy: 0.6201 - val_loss: 1.3732 - val_accuracy: 0.5545
Epoch 128/200
5/5 [==============================] - 1s 181ms/step - loss: 1.0277 - accuracy: 0.5775 - val_loss: 1.3710 - val_accuracy: 0.5572
Epoch 129/200
5/5 [==============================] - 1s 165ms/step - loss: 0.9862 - accuracy: 0.6151 - val_loss: 1.3746 - val_accuracy: 0.5568
Epoch 130/200
5/5 [==============================] - 1s 167ms/step - loss: 0.9637 - accuracy: 0.6345 - val_loss: 1.3762 - val_accuracy: 0.5572
Epoch 131/200
5/5 [==============================] - 1s 140ms/step - loss: 0.9107 - accuracy: 0.6454 - val_loss: 1.3763 - val_accuracy: 0.5591
Epoch 132/200
5/5 [==============================] - 1s 137ms/step - loss: 1.0057 - accuracy: 0.6081 - val_loss: 1.3782 - val_accuracy: 0.5605
Epoch 133/200
5/5 [==============================] - 1s 128ms/step - loss: 0.9786 - accuracy: 0.6209 - val_loss: 1.3788 - val_accuracy: 0.5623
Epoch 134/200
5/5 [==============================] - 1s 123ms/step - loss: 1.0011 - accuracy: 0.5990 - val_loss: 1.3778 - val_accuracy: 0.5651
Epoch 135/200
5/5 [==============================] - 1s 125ms/step - loss: 0.9755 - accuracy: 0.6250 - val_loss: 1.3808 - val_accuracy: 0.5660
Epoch 136/200
5/5 [==============================] - 1s 126ms/step - loss: 0.9770 - accuracy: 0.6175 - val_loss: 1.3842 - val_accuracy: 0.5660
Epoch 137/200
5/5 [==============================] - 1s 127ms/step - loss: 0.9876 - accuracy: 0.6137 - val_loss: 1.3843 - val_accuracy: 0.5679
Epoch 138/200
5/5 [==============================] - 1s 136ms/step - loss: 0.9466 - accuracy: 0.6355 - val_loss: 1.3863 - val_accuracy: 0.5683
Epoch 139/200
5/5 [==============================] - 1s 130ms/step - loss: 0.9569 - accuracy: 0.6377 - val_loss: 1.3873 - val_accuracy: 0.5679
Epoch 140/200
5/5 [==============================] - 1s 129ms/step - loss: 0.9659 - accuracy: 0.6065 - val_loss: 1.3893 - val_accuracy: 0.5693
Epoch 141/200
5/5 [==============================] - 1s 139ms/step - loss: 0.9756 - accuracy: 0.6249 - val_loss: 1.3956 - val_accuracy: 0.5674
Epoch 142/200
5/5 [==============================] - 1s 131ms/step - loss: 0.9219 - accuracy: 0.6481 - val_loss: 1.4022 - val_accuracy: 0.5674
Epoch 143/200
5/5 [==============================] - 1s 130ms/step - loss: 0.9725 - accuracy: 0.6032 - val_loss: 1.4084 - val_accuracy: 0.5683
Epoch 144/200
5/5 [==============================] - 1s 138ms/step - loss: 0.9968 - accuracy: 0.6080 - val_loss: 1.4106 - val_accuracy: 0.5693
Epoch 145/200
5/5 [==============================] - 1s 129ms/step - loss: 0.9467 - accuracy: 0.6306 - val_loss: 1.4139 - val_accuracy: 0.5688
Epoch 146/200
5/5 [==============================] - 1s 130ms/step - loss: 0.9845 - accuracy: 0.5994 - val_loss: 1.4185 - val_accuracy: 0.5683
Epoch 147/200
5/5 [==============================] - 1s 127ms/step - loss: 0.9523 - accuracy: 0.6219 - val_loss: 1.4186 - val_accuracy: 0.5702
Epoch 148/200
5/5 [==============================] - 1s 129ms/step - loss: 0.8707 - accuracy: 0.6598 - val_loss: 1.4205 - val_accuracy: 0.5716
Epoch 149/200
5/5 [==============================] - 1s 123ms/step - loss: 0.8485 - accuracy: 0.6838 - val_loss: 1.4247 - val_accuracy: 0.5716
Epoch 150/200
5/5 [==============================] - 1s 135ms/step - loss: 0.9404 - accuracy: 0.6376 - val_loss: 1.4308 - val_accuracy: 0.5702
Epoch 151/200
5/5 [==============================] - 1s 128ms/step - loss: 0.9460 - accuracy: 0.6284 - val_loss: 1.4369 - val_accuracy: 0.5697
Epoch 152/200
5/5 [==============================] - 1s 132ms/step - loss: 0.9460 - accuracy: 0.6174 - val_loss: 1.4409 - val_accuracy: 0.5725
Epoch 153/200
5/5 [==============================] - 1s 128ms/step - loss: 0.9012 - accuracy: 0.6378 - val_loss: 1.4443 - val_accuracy: 0.5716
Epoch 154/200
5/5 [==============================] - 1s 128ms/step - loss: 0.9226 - accuracy: 0.6226 - val_loss: 1.4550 - val_accuracy: 0.5720
Epoch 155/200
5/5 [==============================] - 1s 130ms/step - loss: 0.9105 - accuracy: 0.6375 - val_loss: 1.4706 - val_accuracy: 0.5697
Epoch 156/200
5/5 [==============================] - 1s 157ms/step - loss: 0.8782 - accuracy: 0.6690 - val_loss: 1.4826 - val_accuracy: 0.5683
Epoch 157/200
5/5 [==============================] - 1s 129ms/step - loss: 0.9039 - accuracy: 0.6218 - val_loss: 1.4903 - val_accuracy: 0.5674
Epoch 158/200
5/5 [==============================] - 1s 135ms/step - loss: 0.9291 - accuracy: 0.6337 - val_loss: 1.4911 - val_accuracy: 0.5697
Epoch 159/200
5/5 [==============================] - 1s 122ms/step - loss: 0.9176 - accuracy: 0.6366 - val_loss: 1.4898 - val_accuracy: 0.5693
Epoch 160/200
5/5 [==============================] - 1s 134ms/step - loss: 0.8564 - accuracy: 0.6516 - val_loss: 1.4861 - val_accuracy: 0.5706
Epoch 161/200
5/5 [==============================] - 1s 127ms/step - loss: 0.8857 - accuracy: 0.6542 - val_loss: 1.4837 - val_accuracy: 0.5739
Epoch 162/200
5/5 [==============================] - 1s 128ms/step - loss: 0.8963 - accuracy: 0.6515 - val_loss: 1.4879 - val_accuracy: 0.5748
Epoch 163/200
5/5 [==============================] - 1s 125ms/step - loss: 0.8920 - accuracy: 0.6548 - val_loss: 1.4925 - val_accuracy: 0.5753
Epoch 164/200
5/5 [==============================] - 1s 123ms/step - loss: 0.8300 - accuracy: 0.6915 - val_loss: 1.5003 - val_accuracy: 0.5753
Epoch 165/200
5/5 [==============================] - 1s 133ms/step - loss: 0.9243 - accuracy: 0.6382 - val_loss: 1.5114 - val_accuracy: 0.5720
Epoch 166/200
5/5 [==============================] - 1s 122ms/step - loss: 0.8374 - accuracy: 0.6702 - val_loss: 1.5212 - val_accuracy: 0.5716
Epoch 167/200
5/5 [==============================] - 1s 127ms/step - loss: 0.8366 - accuracy: 0.6680 - val_loss: 1.5251 - val_accuracy: 0.5702
Epoch 168/200
5/5 [==============================] - 1s 130ms/step - loss: 0.8265 - accuracy: 0.6612 - val_loss: 1.5247 - val_accuracy: 0.5734
Epoch 169/200
5/5 [==============================] - 1s 138ms/step - loss: 0.8960 - accuracy: 0.6386 - val_loss: 1.5208 - val_accuracy: 0.5757
Epoch 170/200
5/5 [==============================] - 1s 144ms/step - loss: 0.8747 - accuracy: 0.6373 - val_loss: 1.5191 - val_accuracy: 0.5771
Epoch 171/200
5/5 [==============================] - 1s 214ms/step - loss: 0.8566 - accuracy: 0.6471 - val_loss: 1.5159 - val_accuracy: 0.5803
Epoch 172/200
5/5 [==============================] - 1s 143ms/step - loss: 0.8520 - accuracy: 0.6547 - val_loss: 1.5122 - val_accuracy: 0.5799
Epoch 173/200
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5/5 [==============================] - 1s 241ms/step - loss: 0.8766 - accuracy: 0.6567 - val_loss: 1.5082 - val_accuracy: 0.5822
Epoch 174/200
5/5 [==============================] - 1s 219ms/step - loss: 0.7819 - accuracy: 0.7044 - val_loss: 1.5063 - val_accuracy: 0.5822
Epoch 175/200
5/5 [==============================] - 1s 184ms/step - loss: 0.8579 - accuracy: 0.6566 - val_loss: 1.5071 - val_accuracy: 0.5822
Epoch 176/200
5/5 [==============================] - 1s 186ms/step - loss: 0.8649 - accuracy: 0.6656 - val_loss: 1.5106 - val_accuracy: 0.5813
Epoch 177/200
5/5 [==============================] - 1s 193ms/step - loss: 0.8462 - accuracy: 0.6377 - val_loss: 1.5143 - val_accuracy: 0.5826
Epoch 178/200
5/5 [==============================] - 1s 175ms/step - loss: 0.8405 - accuracy: 0.6676 - val_loss: 1.5171 - val_accuracy: 0.5845
Epoch 179/200
5/5 [==============================] - 1s 183ms/step - loss: 0.8065 - accuracy: 0.6713 - val_loss: 1.5199 - val_accuracy: 0.5831
Epoch 180/200
5/5 [==============================] - 1s 162ms/step - loss: 0.8850 - accuracy: 0.6369 - val_loss: 1.5232 - val_accuracy: 0.5831
Epoch 181/200
5/5 [==============================] - 1s 216ms/step - loss: 0.8796 - accuracy: 0.6546 - val_loss: 1.5259 - val_accuracy: 0.5826
Epoch 182/200
5/5 [==============================] - 1s 162ms/step - loss: 0.7898 - accuracy: 0.6730 - val_loss: 1.5311 - val_accuracy: 0.5826
Epoch 183/200
5/5 [==============================] - 1s 159ms/step - loss: 0.7982 - accuracy: 0.6828 - val_loss: 1.5380 - val_accuracy: 0.5836
Epoch 184/200
5/5 [==============================] - 1s 156ms/step - loss: 0.8291 - accuracy: 0.6792 - val_loss: 1.5468 - val_accuracy: 0.5836
Epoch 185/200
5/5 [==============================] - 1s 144ms/step - loss: 0.8375 - accuracy: 0.6788 - val_loss: 1.5529 - val_accuracy: 0.5840
Epoch 186/200
5/5 [==============================] - 1s 143ms/step - loss: 0.8144 - accuracy: 0.6788 - val_loss: 1.5538 - val_accuracy: 0.5840
Epoch 187/200
5/5 [==============================] - 1s 130ms/step - loss: 0.8369 - accuracy: 0.6873 - val_loss: 1.5555 - val_accuracy: 0.5836
Epoch 188/200
5/5 [==============================] - 1s 130ms/step - loss: 0.8426 - accuracy: 0.6679 - val_loss: 1.5574 - val_accuracy: 0.5849
Epoch 189/200
5/5 [==============================] - 1s 144ms/step - loss: 0.7954 - accuracy: 0.6879 - val_loss: 1.5557 - val_accuracy: 0.5863
Epoch 190/200
5/5 [==============================] - 1s 131ms/step - loss: 0.7880 - accuracy: 0.6742 - val_loss: 1.5611 - val_accuracy: 0.5854
Epoch 191/200
5/5 [==============================] - 1s 172ms/step - loss: 0.8489 - accuracy: 0.6390 - val_loss: 1.5656 - val_accuracy: 0.5863
Epoch 192/200
5/5 [==============================] - 1s 175ms/step - loss: 0.8292 - accuracy: 0.6736 - val_loss: 1.5664 - val_accuracy: 0.5854
Epoch 193/200
5/5 [==============================] - 1s 151ms/step - loss: 0.7881 - accuracy: 0.6958 - val_loss: 1.5735 - val_accuracy: 0.5854
Epoch 194/200
5/5 [==============================] - 1s 145ms/step - loss: 0.8304 - accuracy: 0.6515 - val_loss: 1.5778 - val_accuracy: 0.5845
Epoch 195/200
5/5 [==============================] - 1s 217ms/step - loss: 0.7969 - accuracy: 0.6696 - val_loss: 1.5797 - val_accuracy: 0.5840
Epoch 196/200
5/5 [==============================] - 1s 183ms/step - loss: 0.7856 - accuracy: 0.6726 - val_loss: 1.5763 - val_accuracy: 0.5854
Epoch 197/200
5/5 [==============================] - 1s 170ms/step - loss: 0.7966 - accuracy: 0.6883 - val_loss: 1.5783 - val_accuracy: 0.5859
Epoch 198/200
5/5 [==============================] - 1s 147ms/step - loss: 0.8072 - accuracy: 0.6626 - val_loss: 1.5819 - val_accuracy: 0.5854
Epoch 199/200
5/5 [==============================] - 1s 135ms/step - loss: 0.7893 - accuracy: 0.6858 - val_loss: 1.5884 - val_accuracy: 0.5849
Epoch 200/200
5/5 [==============================] - 1s 154ms/step - loss: 0.7798 - accuracy: 0.6795 - val_loss: 1.5948 - val_accuracy: 0.5873
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.keras.callbacks.History at 0x14e4a9290&gt;
</pre></div>
</div>
</div>
</div>
</section>
<section id="graph-regularized-version">
<h3>Graph Regularized Version<a class="headerlink" href="#graph-regularized-version" title="Link to this heading">#</a></h3>
<p>We now create the graph-regularized version that uses the citation network information</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">base_model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">([</span><span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">neural_structured_learning</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nsl</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">graph_reg_config</span> <span class="o">=</span> <span class="n">nsl</span><span class="o">.</span><span class="n">configs</span><span class="o">.</span><span class="n">make_graph_reg_config</span><span class="p">(</span>
    <span class="n">max_neighbors</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">multiplier</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">distance_type</span><span class="o">=</span><span class="n">nsl</span><span class="o">.</span><span class="n">configs</span><span class="o">.</span><span class="n">DistanceType</span><span class="o">.</span><span class="n">L2</span><span class="p">,</span>
    <span class="n">sum_over_axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">graph_reg_model</span> <span class="o">=</span> <span class="n">nsl</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">GraphRegularization</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span>
                                                <span class="n">graph_reg_config</span><span class="p">)</span>
<span class="n">graph_reg_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="c1">#graph_reg_model.fit(train_dataset, epochs=200, verbose=1)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">graph_reg_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">myTrain</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="n">myTest</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span>
          <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">TensorBoard</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s1">&#39;/tmp/regularization&#39;</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/200
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/deusebio/.pyenv/versions/3.7.6/envs/ml-book-4/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(&quot;gradient_tape/GraphRegularization/graph_loss/Reshape_1:0&quot;, shape=(None,), dtype=int32), values=Tensor(&quot;gradient_tape/GraphRegularization/graph_loss/Reshape:0&quot;, shape=(None, 7), dtype=float32), dense_shape=Tensor(&quot;gradient_tape/GraphRegularization/graph_loss/Cast:0&quot;, shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.
  &quot;shape. This may consume a large amount of memory.&quot; % value)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5/5 [==============================] - 4s 328ms/step - loss: 2.1052 - accuracy: 0.1049 - scaled_graph_loss: 0.0056 - val_loss: 1.9455 - val_accuracy: 0.1440
Epoch 2/200
5/5 [==============================] - 1s 179ms/step - loss: 2.0342 - accuracy: 0.1722 - scaled_graph_loss: 0.0047 - val_loss: 1.9367 - val_accuracy: 0.1934
Epoch 3/200
5/5 [==============================] - 1s 156ms/step - loss: 1.9881 - accuracy: 0.1603 - scaled_graph_loss: 0.0039 - val_loss: 1.9293 - val_accuracy: 0.2355
Epoch 4/200
5/5 [==============================] - 1s 178ms/step - loss: 1.9918 - accuracy: 0.1816 - scaled_graph_loss: 0.0035 - val_loss: 1.9224 - val_accuracy: 0.2770
Epoch 5/200
5/5 [==============================] - 1s 162ms/step - loss: 1.9551 - accuracy: 0.1983 - scaled_graph_loss: 0.0029 - val_loss: 1.9165 - val_accuracy: 0.2978
Epoch 6/200
5/5 [==============================] - 1s 156ms/step - loss: 1.9745 - accuracy: 0.1918 - scaled_graph_loss: 0.0028 - val_loss: 1.9113 - val_accuracy: 0.3033
Epoch 7/200
5/5 [==============================] - 1s 170ms/step - loss: 1.9490 - accuracy: 0.1762 - scaled_graph_loss: 0.0023 - val_loss: 1.9068 - val_accuracy: 0.3075
Epoch 8/200
5/5 [==============================] - 1s 218ms/step - loss: 1.9262 - accuracy: 0.2016 - scaled_graph_loss: 0.0025 - val_loss: 1.9025 - val_accuracy: 0.3112
Epoch 9/200
5/5 [==============================] - 1s 208ms/step - loss: 1.9413 - accuracy: 0.2383 - scaled_graph_loss: 0.0023 - val_loss: 1.8983 - val_accuracy: 0.3066
Epoch 10/200
5/5 [==============================] - 1s 170ms/step - loss: 1.9136 - accuracy: 0.2278 - scaled_graph_loss: 0.0022 - val_loss: 1.8942 - val_accuracy: 0.3061
Epoch 11/200
5/5 [==============================] - 1s 154ms/step - loss: 1.9232 - accuracy: 0.2413 - scaled_graph_loss: 0.0022 - val_loss: 1.8900 - val_accuracy: 0.3066
Epoch 12/200
5/5 [==============================] - 1s 157ms/step - loss: 1.8885 - accuracy: 0.2682 - scaled_graph_loss: 0.0022 - val_loss: 1.8857 - val_accuracy: 0.3052
Epoch 13/200
5/5 [==============================] - 1s 192ms/step - loss: 1.8657 - accuracy: 0.2789 - scaled_graph_loss: 0.0021 - val_loss: 1.8813 - val_accuracy: 0.3052
Epoch 14/200
5/5 [==============================] - 1s 178ms/step - loss: 1.9115 - accuracy: 0.2158 - scaled_graph_loss: 0.0022 - val_loss: 1.8771 - val_accuracy: 0.3033
Epoch 15/200
5/5 [==============================] - 1s 174ms/step - loss: 1.8700 - accuracy: 0.2652 - scaled_graph_loss: 0.0020 - val_loss: 1.8725 - val_accuracy: 0.3029
Epoch 16/200
5/5 [==============================] - 1s 154ms/step - loss: 1.8883 - accuracy: 0.2607 - scaled_graph_loss: 0.0026 - val_loss: 1.8676 - val_accuracy: 0.3024
Epoch 17/200
5/5 [==============================] - 1s 141ms/step - loss: 1.8588 - accuracy: 0.2631 - scaled_graph_loss: 0.0025 - val_loss: 1.8625 - val_accuracy: 0.3019
Epoch 18/200
5/5 [==============================] - 1s 152ms/step - loss: 1.8774 - accuracy: 0.2593 - scaled_graph_loss: 0.0026 - val_loss: 1.8577 - val_accuracy: 0.3019
Epoch 19/200
5/5 [==============================] - 1s 187ms/step - loss: 1.8376 - accuracy: 0.2726 - scaled_graph_loss: 0.0028 - val_loss: 1.8530 - val_accuracy: 0.3019
Epoch 20/200
5/5 [==============================] - 1s 146ms/step - loss: 1.8590 - accuracy: 0.3045 - scaled_graph_loss: 0.0030 - val_loss: 1.8485 - val_accuracy: 0.3019
Epoch 21/200
5/5 [==============================] - 1s 204ms/step - loss: 1.8240 - accuracy: 0.2647 - scaled_graph_loss: 0.0028 - val_loss: 1.8439 - val_accuracy: 0.3019
Epoch 22/200
5/5 [==============================] - 1s 159ms/step - loss: 1.8541 - accuracy: 0.2940 - scaled_graph_loss: 0.0032 - val_loss: 1.8397 - val_accuracy: 0.3019
Epoch 23/200
5/5 [==============================] - 1s 208ms/step - loss: 1.8121 - accuracy: 0.3230 - scaled_graph_loss: 0.0034 - val_loss: 1.8350 - val_accuracy: 0.3019
Epoch 24/200
5/5 [==============================] - 1s 189ms/step - loss: 1.8325 - accuracy: 0.2986 - scaled_graph_loss: 0.0032 - val_loss: 1.8304 - val_accuracy: 0.3019
Epoch 25/200
5/5 [==============================] - 1s 170ms/step - loss: 1.8066 - accuracy: 0.2818 - scaled_graph_loss: 0.0032 - val_loss: 1.8254 - val_accuracy: 0.3019
Epoch 26/200
5/5 [==============================] - 1s 204ms/step - loss: 1.8389 - accuracy: 0.2880 - scaled_graph_loss: 0.0036 - val_loss: 1.8211 - val_accuracy: 0.3019
Epoch 27/200
5/5 [==============================] - 1s 208ms/step - loss: 1.8070 - accuracy: 0.3068 - scaled_graph_loss: 0.0034 - val_loss: 1.8168 - val_accuracy: 0.3024
Epoch 28/200
5/5 [==============================] - 1s 171ms/step - loss: 1.8070 - accuracy: 0.2909 - scaled_graph_loss: 0.0038 - val_loss: 1.8122 - val_accuracy: 0.3024
Epoch 29/200
5/5 [==============================] - 1s 167ms/step - loss: 1.7793 - accuracy: 0.2947 - scaled_graph_loss: 0.0046 - val_loss: 1.8069 - val_accuracy: 0.3024
Epoch 30/200
5/5 [==============================] - 1s 168ms/step - loss: 1.7738 - accuracy: 0.2886 - scaled_graph_loss: 0.0048 - val_loss: 1.8016 - val_accuracy: 0.3024
Epoch 31/200
5/5 [==============================] - 1s 156ms/step - loss: 1.7596 - accuracy: 0.3011 - scaled_graph_loss: 0.0043 - val_loss: 1.7957 - val_accuracy: 0.3024
Epoch 32/200
5/5 [==============================] - 1s 261ms/step - loss: 1.7768 - accuracy: 0.3165 - scaled_graph_loss: 0.0053 - val_loss: 1.7900 - val_accuracy: 0.3024
Epoch 33/200
5/5 [==============================] - 1s 196ms/step - loss: 1.7419 - accuracy: 0.3019 - scaled_graph_loss: 0.0052 - val_loss: 1.7840 - val_accuracy: 0.3024
Epoch 34/200
5/5 [==============================] - 1s 177ms/step - loss: 1.7615 - accuracy: 0.2834 - scaled_graph_loss: 0.0060 - val_loss: 1.7783 - val_accuracy: 0.3024
Epoch 35/200
5/5 [==============================] - 1s 168ms/step - loss: 1.7419 - accuracy: 0.3210 - scaled_graph_loss: 0.0057 - val_loss: 1.7730 - val_accuracy: 0.3024
Epoch 36/200
5/5 [==============================] - 1s 179ms/step - loss: 1.7253 - accuracy: 0.3277 - scaled_graph_loss: 0.0061 - val_loss: 1.7670 - val_accuracy: 0.3024
Epoch 37/200
5/5 [==============================] - 1s 212ms/step - loss: 1.7170 - accuracy: 0.3362 - scaled_graph_loss: 0.0061 - val_loss: 1.7608 - val_accuracy: 0.3024
Epoch 38/200
5/5 [==============================] - 1s 212ms/step - loss: 1.7038 - accuracy: 0.3185 - scaled_graph_loss: 0.0064 - val_loss: 1.7548 - val_accuracy: 0.3024
Epoch 39/200
5/5 [==============================] - 1s 207ms/step - loss: 1.7044 - accuracy: 0.3301 - scaled_graph_loss: 0.0065 - val_loss: 1.7491 - val_accuracy: 0.3024
Epoch 40/200
5/5 [==============================] - 1s 152ms/step - loss: 1.7011 - accuracy: 0.3390 - scaled_graph_loss: 0.0069 - val_loss: 1.7428 - val_accuracy: 0.3029
Epoch 41/200
5/5 [==============================] - 1s 192ms/step - loss: 1.6931 - accuracy: 0.3415 - scaled_graph_loss: 0.0075 - val_loss: 1.7368 - val_accuracy: 0.3042
Epoch 42/200
5/5 [==============================] - 1s 159ms/step - loss: 1.7035 - accuracy: 0.3211 - scaled_graph_loss: 0.0074 - val_loss: 1.7310 - val_accuracy: 0.3038
Epoch 43/200
5/5 [==============================] - 1s 151ms/step - loss: 1.6884 - accuracy: 0.3293 - scaled_graph_loss: 0.0075 - val_loss: 1.7258 - val_accuracy: 0.3047
Epoch 44/200
5/5 [==============================] - 1s 148ms/step - loss: 1.7046 - accuracy: 0.3319 - scaled_graph_loss: 0.0079 - val_loss: 1.7206 - val_accuracy: 0.3047
Epoch 45/200
5/5 [==============================] - 1s 151ms/step - loss: 1.6325 - accuracy: 0.3369 - scaled_graph_loss: 0.0082 - val_loss: 1.7141 - val_accuracy: 0.3052
Epoch 46/200
5/5 [==============================] - 1s 167ms/step - loss: 1.6682 - accuracy: 0.3413 - scaled_graph_loss: 0.0082 - val_loss: 1.7070 - val_accuracy: 0.3061
Epoch 47/200
5/5 [==============================] - 1s 164ms/step - loss: 1.5976 - accuracy: 0.3434 - scaled_graph_loss: 0.0094 - val_loss: 1.6997 - val_accuracy: 0.3066
Epoch 48/200
5/5 [==============================] - 1s 183ms/step - loss: 1.6572 - accuracy: 0.3536 - scaled_graph_loss: 0.0093 - val_loss: 1.6933 - val_accuracy: 0.3084
Epoch 49/200
5/5 [==============================] - 1s 159ms/step - loss: 1.6508 - accuracy: 0.3540 - scaled_graph_loss: 0.0098 - val_loss: 1.6861 - val_accuracy: 0.3112
Epoch 50/200
5/5 [==============================] - 1s 148ms/step - loss: 1.6408 - accuracy: 0.3250 - scaled_graph_loss: 0.0097 - val_loss: 1.6793 - val_accuracy: 0.3149
Epoch 51/200
5/5 [==============================] - 1s 181ms/step - loss: 1.6336 - accuracy: 0.3462 - scaled_graph_loss: 0.0092 - val_loss: 1.6736 - val_accuracy: 0.3190
Epoch 52/200
5/5 [==============================] - 1s 227ms/step - loss: 1.6309 - accuracy: 0.3321 - scaled_graph_loss: 0.0103 - val_loss: 1.6677 - val_accuracy: 0.3236
Epoch 53/200
5/5 [==============================] - 1s 271ms/step - loss: 1.6388 - accuracy: 0.3596 - scaled_graph_loss: 0.0111 - val_loss: 1.6628 - val_accuracy: 0.3287
Epoch 54/200
5/5 [==============================] - 1s 178ms/step - loss: 1.5818 - accuracy: 0.3541 - scaled_graph_loss: 0.0103 - val_loss: 1.6570 - val_accuracy: 0.3338
Epoch 55/200
5/5 [==============================] - 1s 272ms/step - loss: 1.5723 - accuracy: 0.3685 - scaled_graph_loss: 0.0109 - val_loss: 1.6503 - val_accuracy: 0.3398
Epoch 56/200
5/5 [==============================] - 1s 220ms/step - loss: 1.5742 - accuracy: 0.3803 - scaled_graph_loss: 0.0103 - val_loss: 1.6434 - val_accuracy: 0.3467
Epoch 57/200
5/5 [==============================] - 1s 200ms/step - loss: 1.5509 - accuracy: 0.3862 - scaled_graph_loss: 0.0114 - val_loss: 1.6370 - val_accuracy: 0.3578
Epoch 58/200
5/5 [==============================] - 1s 168ms/step - loss: 1.5821 - accuracy: 0.3674 - scaled_graph_loss: 0.0117 - val_loss: 1.6305 - val_accuracy: 0.3638
Epoch 59/200
5/5 [==============================] - 1s 151ms/step - loss: 1.5852 - accuracy: 0.3616 - scaled_graph_loss: 0.0118 - val_loss: 1.6237 - val_accuracy: 0.3698
Epoch 60/200
5/5 [==============================] - 1s 140ms/step - loss: 1.5499 - accuracy: 0.3611 - scaled_graph_loss: 0.0115 - val_loss: 1.6169 - val_accuracy: 0.3726
Epoch 61/200
5/5 [==============================] - 1s 156ms/step - loss: 1.5457 - accuracy: 0.3744 - scaled_graph_loss: 0.0142 - val_loss: 1.6107 - val_accuracy: 0.3795
Epoch 62/200
5/5 [==============================] - 1s 132ms/step - loss: 1.5397 - accuracy: 0.3819 - scaled_graph_loss: 0.0127 - val_loss: 1.6045 - val_accuracy: 0.3892
Epoch 63/200
5/5 [==============================] - 1s 153ms/step - loss: 1.5438 - accuracy: 0.4087 - scaled_graph_loss: 0.0136 - val_loss: 1.5984 - val_accuracy: 0.3947
Epoch 64/200
5/5 [==============================] - 1s 162ms/step - loss: 1.5161 - accuracy: 0.3815 - scaled_graph_loss: 0.0135 - val_loss: 1.5919 - val_accuracy: 0.4017
Epoch 65/200
5/5 [==============================] - 1s 143ms/step - loss: 1.5581 - accuracy: 0.3713 - scaled_graph_loss: 0.0134 - val_loss: 1.5854 - val_accuracy: 0.4086
Epoch 66/200
5/5 [==============================] - 1s 138ms/step - loss: 1.5347 - accuracy: 0.3858 - scaled_graph_loss: 0.0122 - val_loss: 1.5794 - val_accuracy: 0.4197
Epoch 67/200
5/5 [==============================] - 1s 204ms/step - loss: 1.4917 - accuracy: 0.4024 - scaled_graph_loss: 0.0141 - val_loss: 1.5733 - val_accuracy: 0.4326
Epoch 68/200
5/5 [==============================] - 1s 223ms/step - loss: 1.4804 - accuracy: 0.3927 - scaled_graph_loss: 0.0129 - val_loss: 1.5658 - val_accuracy: 0.4483
Epoch 69/200
5/5 [==============================] - 1s 252ms/step - loss: 1.4751 - accuracy: 0.4093 - scaled_graph_loss: 0.0138 - val_loss: 1.5586 - val_accuracy: 0.4575
Epoch 70/200
5/5 [==============================] - 1s 192ms/step - loss: 1.4870 - accuracy: 0.4230 - scaled_graph_loss: 0.0140 - val_loss: 1.5514 - val_accuracy: 0.4645
Epoch 71/200
5/5 [==============================] - 1s 213ms/step - loss: 1.4541 - accuracy: 0.4380 - scaled_graph_loss: 0.0146 - val_loss: 1.5447 - val_accuracy: 0.4686
Epoch 72/200
5/5 [==============================] - 1s 264ms/step - loss: 1.4528 - accuracy: 0.4193 - scaled_graph_loss: 0.0141 - val_loss: 1.5373 - val_accuracy: 0.4765
Epoch 73/200
5/5 [==============================] - 1s 199ms/step - loss: 1.4318 - accuracy: 0.4144 - scaled_graph_loss: 0.0177 - val_loss: 1.5302 - val_accuracy: 0.4820
Epoch 74/200
5/5 [==============================] - 1s 210ms/step - loss: 1.4495 - accuracy: 0.4282 - scaled_graph_loss: 0.0161 - val_loss: 1.5239 - val_accuracy: 0.4926
Epoch 75/200
5/5 [==============================] - 1s 164ms/step - loss: 1.4085 - accuracy: 0.4447 - scaled_graph_loss: 0.0161 - val_loss: 1.5170 - val_accuracy: 0.4958
Epoch 76/200
5/5 [==============================] - 1s 171ms/step - loss: 1.3982 - accuracy: 0.4639 - scaled_graph_loss: 0.0155 - val_loss: 1.5103 - val_accuracy: 0.5000
Epoch 77/200
5/5 [==============================] - 1s 186ms/step - loss: 1.3995 - accuracy: 0.4773 - scaled_graph_loss: 0.0168 - val_loss: 1.5037 - val_accuracy: 0.5037
Epoch 78/200
5/5 [==============================] - 1s 179ms/step - loss: 1.4244 - accuracy: 0.4426 - scaled_graph_loss: 0.0185 - val_loss: 1.4985 - val_accuracy: 0.5074
Epoch 79/200
5/5 [==============================] - 1s 194ms/step - loss: 1.4186 - accuracy: 0.4440 - scaled_graph_loss: 0.0163 - val_loss: 1.4933 - val_accuracy: 0.5102
Epoch 80/200
5/5 [==============================] - 1s 212ms/step - loss: 1.3805 - accuracy: 0.4560 - scaled_graph_loss: 0.0170 - val_loss: 1.4872 - val_accuracy: 0.5115
Epoch 81/200
5/5 [==============================] - 1s 204ms/step - loss: 1.3641 - accuracy: 0.4687 - scaled_graph_loss: 0.0173 - val_loss: 1.4800 - val_accuracy: 0.5166
Epoch 82/200
5/5 [==============================] - 1s 207ms/step - loss: 1.3796 - accuracy: 0.4717 - scaled_graph_loss: 0.0164 - val_loss: 1.4728 - val_accuracy: 0.5249
Epoch 83/200
5/5 [==============================] - 1s 203ms/step - loss: 1.4130 - accuracy: 0.4492 - scaled_graph_loss: 0.0177 - val_loss: 1.4667 - val_accuracy: 0.5314
Epoch 84/200
5/5 [==============================] - 1s 222ms/step - loss: 1.3239 - accuracy: 0.4916 - scaled_graph_loss: 0.0197 - val_loss: 1.4608 - val_accuracy: 0.5369
Epoch 85/200
5/5 [==============================] - 1s 220ms/step - loss: 1.3893 - accuracy: 0.4488 - scaled_graph_loss: 0.0186 - val_loss: 1.4551 - val_accuracy: 0.5434
Epoch 86/200
5/5 [==============================] - 1s 236ms/step - loss: 1.3161 - accuracy: 0.4909 - scaled_graph_loss: 0.0204 - val_loss: 1.4490 - val_accuracy: 0.5466
Epoch 87/200
5/5 [==============================] - 1s 179ms/step - loss: 1.3434 - accuracy: 0.4966 - scaled_graph_loss: 0.0200 - val_loss: 1.4419 - val_accuracy: 0.5476
Epoch 88/200
5/5 [==============================] - 1s 250ms/step - loss: 1.3027 - accuracy: 0.5098 - scaled_graph_loss: 0.0196 - val_loss: 1.4357 - val_accuracy: 0.5489
Epoch 89/200
5/5 [==============================] - 1s 230ms/step - loss: 1.3019 - accuracy: 0.4970 - scaled_graph_loss: 0.0201 - val_loss: 1.4293 - val_accuracy: 0.5526
Epoch 90/200
5/5 [==============================] - 1s 248ms/step - loss: 1.2992 - accuracy: 0.4944 - scaled_graph_loss: 0.0205 - val_loss: 1.4230 - val_accuracy: 0.5559
Epoch 91/200
5/5 [==============================] - 1s 231ms/step - loss: 1.3239 - accuracy: 0.4901 - scaled_graph_loss: 0.0179 - val_loss: 1.4171 - val_accuracy: 0.5619
Epoch 92/200
5/5 [==============================] - 1s 221ms/step - loss: 1.3136 - accuracy: 0.5136 - scaled_graph_loss: 0.0196 - val_loss: 1.4112 - val_accuracy: 0.5669
Epoch 93/200
5/5 [==============================] - 1s 183ms/step - loss: 1.2639 - accuracy: 0.5288 - scaled_graph_loss: 0.0209 - val_loss: 1.4053 - val_accuracy: 0.5665
Epoch 94/200
5/5 [==============================] - 1s 205ms/step - loss: 1.2763 - accuracy: 0.5047 - scaled_graph_loss: 0.0209 - val_loss: 1.3995 - val_accuracy: 0.5665
Epoch 95/200
5/5 [==============================] - 1s 238ms/step - loss: 1.2617 - accuracy: 0.5052 - scaled_graph_loss: 0.0207 - val_loss: 1.3948 - val_accuracy: 0.5656
Epoch 96/200
5/5 [==============================] - 1s 218ms/step - loss: 1.2874 - accuracy: 0.5022 - scaled_graph_loss: 0.0226 - val_loss: 1.3906 - val_accuracy: 0.5697
Epoch 97/200
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5/5 [==============================] - 1s 256ms/step - loss: 1.2262 - accuracy: 0.5307 - scaled_graph_loss: 0.0216 - val_loss: 1.3858 - val_accuracy: 0.5702
Epoch 98/200
5/5 [==============================] - 1s 197ms/step - loss: 1.2362 - accuracy: 0.5532 - scaled_graph_loss: 0.0216 - val_loss: 1.3793 - val_accuracy: 0.5725
Epoch 99/200
5/5 [==============================] - 1s 262ms/step - loss: 1.2081 - accuracy: 0.5314 - scaled_graph_loss: 0.0236 - val_loss: 1.3731 - val_accuracy: 0.5748
Epoch 100/200
5/5 [==============================] - 1s 160ms/step - loss: 1.2115 - accuracy: 0.5213 - scaled_graph_loss: 0.0224 - val_loss: 1.3678 - val_accuracy: 0.5780
Epoch 101/200
5/5 [==============================] - 1s 153ms/step - loss: 1.1994 - accuracy: 0.5480 - scaled_graph_loss: 0.0230 - val_loss: 1.3620 - val_accuracy: 0.5785
Epoch 102/200
5/5 [==============================] - 1s 144ms/step - loss: 1.1956 - accuracy: 0.5351 - scaled_graph_loss: 0.0240 - val_loss: 1.3569 - val_accuracy: 0.5799
Epoch 103/200
5/5 [==============================] - 1s 154ms/step - loss: 1.2904 - accuracy: 0.4833 - scaled_graph_loss: 0.0225 - val_loss: 1.3529 - val_accuracy: 0.5803
Epoch 104/200
5/5 [==============================] - 1s 210ms/step - loss: 1.1866 - accuracy: 0.5519 - scaled_graph_loss: 0.0241 - val_loss: 1.3486 - val_accuracy: 0.5799
Epoch 105/200
5/5 [==============================] - 1s 184ms/step - loss: 1.2259 - accuracy: 0.5028 - scaled_graph_loss: 0.0225 - val_loss: 1.3449 - val_accuracy: 0.5822
Epoch 106/200
5/5 [==============================] - 1s 218ms/step - loss: 1.2135 - accuracy: 0.5383 - scaled_graph_loss: 0.0246 - val_loss: 1.3409 - val_accuracy: 0.5826
Epoch 107/200
5/5 [==============================] - 1s 215ms/step - loss: 1.1978 - accuracy: 0.5241 - scaled_graph_loss: 0.0244 - val_loss: 1.3366 - val_accuracy: 0.5831
Epoch 108/200
5/5 [==============================] - 1s 214ms/step - loss: 1.1885 - accuracy: 0.5566 - scaled_graph_loss: 0.0250 - val_loss: 1.3322 - val_accuracy: 0.5845
Epoch 109/200
5/5 [==============================] - 1s 168ms/step - loss: 1.1876 - accuracy: 0.5501 - scaled_graph_loss: 0.0258 - val_loss: 1.3270 - val_accuracy: 0.5877
Epoch 110/200
5/5 [==============================] - 1s 172ms/step - loss: 1.1515 - accuracy: 0.5736 - scaled_graph_loss: 0.0251 - val_loss: 1.3238 - val_accuracy: 0.5896
Epoch 111/200
5/5 [==============================] - 1s 166ms/step - loss: 1.1388 - accuracy: 0.5336 - scaled_graph_loss: 0.0248 - val_loss: 1.3204 - val_accuracy: 0.5910
Epoch 112/200
5/5 [==============================] - 1s 176ms/step - loss: 1.1100 - accuracy: 0.5436 - scaled_graph_loss: 0.0266 - val_loss: 1.3165 - val_accuracy: 0.5928
Epoch 113/200
5/5 [==============================] - 1s 158ms/step - loss: 1.1504 - accuracy: 0.5861 - scaled_graph_loss: 0.0254 - val_loss: 1.3145 - val_accuracy: 0.5910
Epoch 114/200
5/5 [==============================] - 1s 214ms/step - loss: 1.1706 - accuracy: 0.5344 - scaled_graph_loss: 0.0262 - val_loss: 1.3123 - val_accuracy: 0.5905
Epoch 115/200
5/5 [==============================] - 1s 164ms/step - loss: 1.1645 - accuracy: 0.5694 - scaled_graph_loss: 0.0257 - val_loss: 1.3099 - val_accuracy: 0.5905
Epoch 116/200
5/5 [==============================] - 1s 227ms/step - loss: 1.1480 - accuracy: 0.5713 - scaled_graph_loss: 0.0249 - val_loss: 1.3066 - val_accuracy: 0.5919
Epoch 117/200
5/5 [==============================] - 1s 194ms/step - loss: 1.1302 - accuracy: 0.5679 - scaled_graph_loss: 0.0253 - val_loss: 1.3026 - val_accuracy: 0.5937
Epoch 118/200
5/5 [==============================] - 1s 137ms/step - loss: 1.1127 - accuracy: 0.5759 - scaled_graph_loss: 0.0240 - val_loss: 1.3002 - val_accuracy: 0.5942
Epoch 119/200
5/5 [==============================] - 1s 209ms/step - loss: 1.1154 - accuracy: 0.5697 - scaled_graph_loss: 0.0271 - val_loss: 1.2991 - val_accuracy: 0.5942
Epoch 120/200
5/5 [==============================] - 1s 187ms/step - loss: 1.0834 - accuracy: 0.5843 - scaled_graph_loss: 0.0245 - val_loss: 1.2963 - val_accuracy: 0.5951
Epoch 121/200
5/5 [==============================] - 1s 156ms/step - loss: 1.1061 - accuracy: 0.5903 - scaled_graph_loss: 0.0258 - val_loss: 1.2935 - val_accuracy: 0.5965
Epoch 122/200
5/5 [==============================] - 1s 167ms/step - loss: 1.0833 - accuracy: 0.5821 - scaled_graph_loss: 0.0254 - val_loss: 1.2900 - val_accuracy: 0.5970
Epoch 123/200
5/5 [==============================] - 1s 175ms/step - loss: 1.1348 - accuracy: 0.5637 - scaled_graph_loss: 0.0248 - val_loss: 1.2858 - val_accuracy: 0.5988
Epoch 124/200
5/5 [==============================] - 1s 170ms/step - loss: 1.0713 - accuracy: 0.5912 - scaled_graph_loss: 0.0252 - val_loss: 1.2819 - val_accuracy: 0.5997
Epoch 125/200
5/5 [==============================] - 1s 176ms/step - loss: 1.0583 - accuracy: 0.5960 - scaled_graph_loss: 0.0277 - val_loss: 1.2799 - val_accuracy: 0.6006
Epoch 126/200
5/5 [==============================] - 1s 179ms/step - loss: 1.0950 - accuracy: 0.6009 - scaled_graph_loss: 0.0253 - val_loss: 1.2770 - val_accuracy: 0.5993
Epoch 127/200
5/5 [==============================] - 1s 163ms/step - loss: 1.1018 - accuracy: 0.5771 - scaled_graph_loss: 0.0259 - val_loss: 1.2736 - val_accuracy: 0.6020
Epoch 128/200
5/5 [==============================] - 1s 147ms/step - loss: 1.1109 - accuracy: 0.5796 - scaled_graph_loss: 0.0273 - val_loss: 1.2704 - val_accuracy: 0.6016
Epoch 129/200
5/5 [==============================] - 1s 142ms/step - loss: 1.0983 - accuracy: 0.5808 - scaled_graph_loss: 0.0266 - val_loss: 1.2668 - val_accuracy: 0.6034
Epoch 130/200
5/5 [==============================] - 1s 135ms/step - loss: 1.1054 - accuracy: 0.5490 - scaled_graph_loss: 0.0296 - val_loss: 1.2626 - val_accuracy: 0.6066
Epoch 131/200
5/5 [==============================] - 1s 136ms/step - loss: 1.0896 - accuracy: 0.6092 - scaled_graph_loss: 0.0295 - val_loss: 1.2595 - val_accuracy: 0.6080
Epoch 132/200
5/5 [==============================] - 1s 148ms/step - loss: 1.0911 - accuracy: 0.5874 - scaled_graph_loss: 0.0292 - val_loss: 1.2571 - val_accuracy: 0.6076
Epoch 133/200
5/5 [==============================] - 1s 149ms/step - loss: 1.1144 - accuracy: 0.5697 - scaled_graph_loss: 0.0279 - val_loss: 1.2532 - val_accuracy: 0.6094
Epoch 134/200
5/5 [==============================] - 1s 140ms/step - loss: 1.0619 - accuracy: 0.5921 - scaled_graph_loss: 0.0314 - val_loss: 1.2494 - val_accuracy: 0.6103
Epoch 135/200
5/5 [==============================] - 1s 152ms/step - loss: 1.0882 - accuracy: 0.5957 - scaled_graph_loss: 0.0283 - val_loss: 1.2506 - val_accuracy: 0.6094
Epoch 136/200
5/5 [==============================] - 1s 181ms/step - loss: 1.0127 - accuracy: 0.6250 - scaled_graph_loss: 0.0296 - val_loss: 1.2510 - val_accuracy: 0.6090
Epoch 137/200
5/5 [==============================] - 1s 157ms/step - loss: 1.0254 - accuracy: 0.6049 - scaled_graph_loss: 0.0278 - val_loss: 1.2501 - val_accuracy: 0.6103
Epoch 138/200
5/5 [==============================] - 1s 145ms/step - loss: 1.0017 - accuracy: 0.6117 - scaled_graph_loss: 0.0298 - val_loss: 1.2472 - val_accuracy: 0.6108
Epoch 139/200
5/5 [==============================] - 1s 155ms/step - loss: 1.0102 - accuracy: 0.6226 - scaled_graph_loss: 0.0277 - val_loss: 1.2472 - val_accuracy: 0.6117
Epoch 140/200
5/5 [==============================] - 1s 187ms/step - loss: 1.0174 - accuracy: 0.6061 - scaled_graph_loss: 0.0314 - val_loss: 1.2470 - val_accuracy: 0.6127
Epoch 141/200
5/5 [==============================] - 1s 175ms/step - loss: 1.0487 - accuracy: 0.6027 - scaled_graph_loss: 0.0279 - val_loss: 1.2464 - val_accuracy: 0.6131
Epoch 142/200
5/5 [==============================] - 1s 164ms/step - loss: 1.0059 - accuracy: 0.5976 - scaled_graph_loss: 0.0290 - val_loss: 1.2446 - val_accuracy: 0.6131
Epoch 143/200
5/5 [==============================] - 1s 209ms/step - loss: 0.9457 - accuracy: 0.6522 - scaled_graph_loss: 0.0272 - val_loss: 1.2440 - val_accuracy: 0.6131
Epoch 144/200
5/5 [==============================] - 1s 176ms/step - loss: 1.0196 - accuracy: 0.6143 - scaled_graph_loss: 0.0281 - val_loss: 1.2449 - val_accuracy: 0.6136
Epoch 145/200
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5/5 [==============================] - 1s 222ms/step - loss: 1.0264 - accuracy: 0.6045 - scaled_graph_loss: 0.0281 - val_loss: 1.2458 - val_accuracy: 0.6136
Epoch 146/200
5/5 [==============================] - 1s 181ms/step - loss: 0.9464 - accuracy: 0.6266 - scaled_graph_loss: 0.0315 - val_loss: 1.2463 - val_accuracy: 0.6136
Epoch 147/200
5/5 [==============================] - 1s 191ms/step - loss: 1.0403 - accuracy: 0.5913 - scaled_graph_loss: 0.0275 - val_loss: 1.2475 - val_accuracy: 0.6127
Epoch 148/200
5/5 [==============================] - 1s 231ms/step - loss: 1.0299 - accuracy: 0.6055 - scaled_graph_loss: 0.0302 - val_loss: 1.2493 - val_accuracy: 0.6127
Epoch 149/200
5/5 [==============================] - 1s 174ms/step - loss: 1.0777 - accuracy: 0.5722 - scaled_graph_loss: 0.0313 - val_loss: 1.2508 - val_accuracy: 0.6127
Epoch 150/200
5/5 [==============================] - 1s 265ms/step - loss: 1.0012 - accuracy: 0.6296 - scaled_graph_loss: 0.0288 - val_loss: 1.2516 - val_accuracy: 0.6131
Epoch 151/200
5/5 [==============================] - 1s 256ms/step - loss: 0.9506 - accuracy: 0.6113 - scaled_graph_loss: 0.0292 - val_loss: 1.2499 - val_accuracy: 0.6136
Epoch 152/200
5/5 [==============================] - 1s 250ms/step - loss: 1.0039 - accuracy: 0.6003 - scaled_graph_loss: 0.0286 - val_loss: 1.2448 - val_accuracy: 0.6145
Epoch 153/200
5/5 [==============================] - 1s 239ms/step - loss: 0.9514 - accuracy: 0.6343 - scaled_graph_loss: 0.0299 - val_loss: 1.2397 - val_accuracy: 0.6154
Epoch 154/200
5/5 [==============================] - 1s 199ms/step - loss: 0.9848 - accuracy: 0.6177 - scaled_graph_loss: 0.0309 - val_loss: 1.2356 - val_accuracy: 0.6177
Epoch 155/200
5/5 [==============================] - 1s 163ms/step - loss: 0.9157 - accuracy: 0.6665 - scaled_graph_loss: 0.0314 - val_loss: 1.2342 - val_accuracy: 0.6177
Epoch 156/200
5/5 [==============================] - 1s 160ms/step - loss: 0.9497 - accuracy: 0.6200 - scaled_graph_loss: 0.0301 - val_loss: 1.2320 - val_accuracy: 0.6177
Epoch 157/200
5/5 [==============================] - 1s 172ms/step - loss: 0.9808 - accuracy: 0.6151 - scaled_graph_loss: 0.0309 - val_loss: 1.2295 - val_accuracy: 0.6200
Epoch 158/200
5/5 [==============================] - 1s 181ms/step - loss: 0.9169 - accuracy: 0.6518 - scaled_graph_loss: 0.0283 - val_loss: 1.2264 - val_accuracy: 0.6219
Epoch 159/200
5/5 [==============================] - 1s 168ms/step - loss: 1.0104 - accuracy: 0.6188 - scaled_graph_loss: 0.0289 - val_loss: 1.2250 - val_accuracy: 0.6228
Epoch 160/200
5/5 [==============================] - 1s 180ms/step - loss: 0.9568 - accuracy: 0.5875 - scaled_graph_loss: 0.0311 - val_loss: 1.2251 - val_accuracy: 0.6219
Epoch 161/200
5/5 [==============================] - 1s 162ms/step - loss: 0.9131 - accuracy: 0.6352 - scaled_graph_loss: 0.0303 - val_loss: 1.2244 - val_accuracy: 0.6219
Epoch 162/200
5/5 [==============================] - 1s 168ms/step - loss: 0.9322 - accuracy: 0.6390 - scaled_graph_loss: 0.0308 - val_loss: 1.2250 - val_accuracy: 0.6223
Epoch 163/200
5/5 [==============================] - 1s 191ms/step - loss: 0.9138 - accuracy: 0.6420 - scaled_graph_loss: 0.0309 - val_loss: 1.2265 - val_accuracy: 0.6223
Epoch 164/200
5/5 [==============================] - 1s 161ms/step - loss: 0.9189 - accuracy: 0.6483 - scaled_graph_loss: 0.0310 - val_loss: 1.2288 - val_accuracy: 0.6214
Epoch 165/200
5/5 [==============================] - 1s 167ms/step - loss: 0.9210 - accuracy: 0.6330 - scaled_graph_loss: 0.0331 - val_loss: 1.2299 - val_accuracy: 0.6228
Epoch 166/200
5/5 [==============================] - 1s 201ms/step - loss: 0.9685 - accuracy: 0.6292 - scaled_graph_loss: 0.0329 - val_loss: 1.2324 - val_accuracy: 0.6251
Epoch 167/200
5/5 [==============================] - 1s 260ms/step - loss: 0.9593 - accuracy: 0.6231 - scaled_graph_loss: 0.0320 - val_loss: 1.2372 - val_accuracy: 0.6251
Epoch 168/200
5/5 [==============================] - 1s 186ms/step - loss: 0.9453 - accuracy: 0.6082 - scaled_graph_loss: 0.0301 - val_loss: 1.2409 - val_accuracy: 0.6260
Epoch 169/200
5/5 [==============================] - 1s 174ms/step - loss: 1.0013 - accuracy: 0.6015 - scaled_graph_loss: 0.0313 - val_loss: 1.2456 - val_accuracy: 0.6247
Epoch 170/200
5/5 [==============================] - 1s 225ms/step - loss: 0.9140 - accuracy: 0.6605 - scaled_graph_loss: 0.0311 - val_loss: 1.2488 - val_accuracy: 0.6228
Epoch 171/200
5/5 [==============================] - 1s 184ms/step - loss: 0.8999 - accuracy: 0.6485 - scaled_graph_loss: 0.0295 - val_loss: 1.2475 - val_accuracy: 0.6237
Epoch 172/200
5/5 [==============================] - 1s 163ms/step - loss: 0.9913 - accuracy: 0.6180 - scaled_graph_loss: 0.0299 - val_loss: 1.2500 - val_accuracy: 0.6242
Epoch 173/200
5/5 [==============================] - 1s 229ms/step - loss: 0.9542 - accuracy: 0.6138 - scaled_graph_loss: 0.0290 - val_loss: 1.2513 - val_accuracy: 0.6237
Epoch 174/200
5/5 [==============================] - 1s 283ms/step - loss: 0.9251 - accuracy: 0.6392 - scaled_graph_loss: 0.0309 - val_loss: 1.2524 - val_accuracy: 0.6247
Epoch 175/200
5/5 [==============================] - 1s 277ms/step - loss: 0.9016 - accuracy: 0.6572 - scaled_graph_loss: 0.0321 - val_loss: 1.2525 - val_accuracy: 0.6260
Epoch 176/200
5/5 [==============================] - 1s 271ms/step - loss: 0.9267 - accuracy: 0.6182 - scaled_graph_loss: 0.0311 - val_loss: 1.2514 - val_accuracy: 0.6260
Epoch 177/200
5/5 [==============================] - 1s 231ms/step - loss: 0.8702 - accuracy: 0.6715 - scaled_graph_loss: 0.0307 - val_loss: 1.2500 - val_accuracy: 0.6265
Epoch 178/200
5/5 [==============================] - 1s 179ms/step - loss: 0.8859 - accuracy: 0.6498 - scaled_graph_loss: 0.0300 - val_loss: 1.2444 - val_accuracy: 0.6260
Epoch 179/200
5/5 [==============================] - 1s 232ms/step - loss: 0.9165 - accuracy: 0.6484 - scaled_graph_loss: 0.0306 - val_loss: 1.2410 - val_accuracy: 0.6265
Epoch 180/200
5/5 [==============================] - 1s 269ms/step - loss: 0.8989 - accuracy: 0.6480 - scaled_graph_loss: 0.0308 - val_loss: 1.2395 - val_accuracy: 0.6260
Epoch 181/200
5/5 [==============================] - 1s 280ms/step - loss: 0.9084 - accuracy: 0.6570 - scaled_graph_loss: 0.0303 - val_loss: 1.2380 - val_accuracy: 0.6270
Epoch 182/200
5/5 [==============================] - 1s 184ms/step - loss: 0.8927 - accuracy: 0.6529 - scaled_graph_loss: 0.0321 - val_loss: 1.2398 - val_accuracy: 0.6293
Epoch 183/200
5/5 [==============================] - 1s 269ms/step - loss: 0.9331 - accuracy: 0.6413 - scaled_graph_loss: 0.0324 - val_loss: 1.2425 - val_accuracy: 0.6274
Epoch 184/200
5/5 [==============================] - 1s 232ms/step - loss: 0.8546 - accuracy: 0.6809 - scaled_graph_loss: 0.0297 - val_loss: 1.2477 - val_accuracy: 0.6283
Epoch 185/200
5/5 [==============================] - 1s 195ms/step - loss: 0.8826 - accuracy: 0.6345 - scaled_graph_loss: 0.0327 - val_loss: 1.2524 - val_accuracy: 0.6274
Epoch 186/200
5/5 [==============================] - 1s 234ms/step - loss: 0.8374 - accuracy: 0.6524 - scaled_graph_loss: 0.0321 - val_loss: 1.2602 - val_accuracy: 0.6288
Epoch 187/200
5/5 [==============================] - 1s 240ms/step - loss: 0.9199 - accuracy: 0.6291 - scaled_graph_loss: 0.0331 - val_loss: 1.2633 - val_accuracy: 0.6279
Epoch 188/200
5/5 [==============================] - 1s 198ms/step - loss: 0.8474 - accuracy: 0.6932 - scaled_graph_loss: 0.0315 - val_loss: 1.2667 - val_accuracy: 0.6270
Epoch 189/200
5/5 [==============================] - 1s 162ms/step - loss: 0.8857 - accuracy: 0.6527 - scaled_graph_loss: 0.0326 - val_loss: 1.2682 - val_accuracy: 0.6251
Epoch 190/200
5/5 [==============================] - 1s 167ms/step - loss: 0.8189 - accuracy: 0.6870 - scaled_graph_loss: 0.0335 - val_loss: 1.2717 - val_accuracy: 0.6251
Epoch 191/200
5/5 [==============================] - 1s 157ms/step - loss: 0.9053 - accuracy: 0.6332 - scaled_graph_loss: 0.0321 - val_loss: 1.2757 - val_accuracy: 0.6233
Epoch 192/200
5/5 [==============================] - 1s 156ms/step - loss: 0.9003 - accuracy: 0.6519 - scaled_graph_loss: 0.0333 - val_loss: 1.2747 - val_accuracy: 0.6256
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 193/200
5/5 [==============================] - 1s 165ms/step - loss: 0.8634 - accuracy: 0.6420 - scaled_graph_loss: 0.0301 - val_loss: 1.2704 - val_accuracy: 0.6270
Epoch 194/200
5/5 [==============================] - 1s 164ms/step - loss: 0.8267 - accuracy: 0.6727 - scaled_graph_loss: 0.0314 - val_loss: 1.2641 - val_accuracy: 0.6274
Epoch 195/200
5/5 [==============================] - 1s 172ms/step - loss: 0.8430 - accuracy: 0.6941 - scaled_graph_loss: 0.0338 - val_loss: 1.2606 - val_accuracy: 0.6283
Epoch 196/200
5/5 [==============================] - 1s 177ms/step - loss: 0.8967 - accuracy: 0.6375 - scaled_graph_loss: 0.0320 - val_loss: 1.2575 - val_accuracy: 0.6316
Epoch 197/200
5/5 [==============================] - 1s 164ms/step - loss: 0.8748 - accuracy: 0.6446 - scaled_graph_loss: 0.0315 - val_loss: 1.2558 - val_accuracy: 0.6320
Epoch 198/200
5/5 [==============================] - 1s 190ms/step - loss: 0.9019 - accuracy: 0.6390 - scaled_graph_loss: 0.0323 - val_loss: 1.2531 - val_accuracy: 0.6316
Epoch 199/200
5/5 [==============================] - 1s 139ms/step - loss: 0.7997 - accuracy: 0.6777 - scaled_graph_loss: 0.0342 - val_loss: 1.2514 - val_accuracy: 0.6325
Epoch 200/200
5/5 [==============================] - 1s 247ms/step - loss: 0.9136 - accuracy: 0.6405 - scaled_graph_loss: 0.0328 - val_loss: 1.2526 - val_accuracy: 0.6320
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.keras.callbacks.History at 0x14fe35610&gt;
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "mlgbook"
        },
        kernelOptions: {
            name: "mlgbook",
            path: "./content\Chapter04"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'mlgbook'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="02_Shallow_embeddings.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Utility graph plot matrix</p>
      </div>
    </a>
    <a class="right-next"
       href="04_Graph_Neural_Networks.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Shallow methods for supervised learning</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-dataset">Load Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-the-model">Creating the model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vanilla-model">Vanilla Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-regularized-version">Graph Regularized Version</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Soheila Ashkezari-T.
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
       Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07191c19-0a85-4bf3-aaa7-4f0e8f3e4e8d",
   "metadata": {},
   "source": [
    "# Chapter 3 : Unsupervised Graph learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082a0b6e-1290-4e1e-9b12-96f870073656",
   "metadata": {},
   "source": [
    "## Unsupervised machine learning \n",
    "\n",
    "Unsupervised machine learning refers to a category of algorithms that can learn patterns from data without relying on labeled examples. In the context of graph data, these algorithms are particularly valuable because they **operate using only the graph structure (e.g., adjacency matrix) and optionally node features**, without requiring any prior knowledge of specific tasks such as classification or regression.\n",
    "\n",
    "A widely adopted strategy in unsupervised graph learning is to **learn node or graph embeddings**â€”that is, low-dimensional vector representations that capture the structure and relationships within the graph. These embeddings are typically optimized to preserve similarity between nodes or substructures, enabling the reconstruction of relationships like those expressed in the adjacency matrix.\n",
    "\n",
    "What makes this approach powerful is that the **learned representations can encode latent and abstract patterns, revealing complex dependencies or communities that are not explicitly observable in the original data**. \n",
    "\n",
    "As a result, **these embeddings serve as rich feature sets** for various downstream tasks such as node clustering, link prediction, and anomaly detectionâ€”even though no supervision was provided during training."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60673d94-ad88-4f06-88d4-5b14a61c9b51",
   "metadata": {},
   "source": [
    "![unsupervisedLearning](../images/chap1_5.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46c88c7-7336-46d5-9a3b-21199296bae2",
   "metadata": {},
   "source": [
    "## Unsupervised Learning for Graph Data\n",
    "\n",
    "This diagram categorizes the main approaches for unsupervised machine learning on graph-structured data, specifically focusing on representation learning:\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¹ 1. Shallow Embedding\n",
    "- **Idea:** Learn a fixed vector (embedding) for each node, edge, or graph using simplified models.\n",
    "\n",
    "\n",
    "- **Matrix Factorization-based Methods:**\n",
    "  - Learn embeddings by factorizing similarity matrices (e.g., adjacency matrix).\n",
    "  - **Examples:** `HOPE`, `GraphRep`, `Graph Factorization`\n",
    "\n",
    "- **Skip-gram-based Methods:**\n",
    "  - Inspired by word2vec; learn embeddings based on local node neighborhoods.\n",
    "  - **Examples:** `Node2Vec`, `Edge2Vec`, `Graph2Vec`\n",
    "\n",
    "- **Usage:** \n",
    "  - The learned embeddings can be used as input features for traditional supervised or unsupervised models (e.g., SVM, KMeans).\n",
    "- **Characteristics:** \n",
    "  - Simple architecture.\n",
    "  - Embedding and learning are decoupled.\n",
    "  - Cannot adapt embeddings during downstream tasks.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¸ 2. Autoencoders\n",
    "- **Idea:** Learn to encode the graph structure into a low-dimensional latent space and reconstruct it.\n",
    "\n",
    "- Capture non-linear relationships between nodes.\n",
    "\n",
    "- **Components:**\n",
    "  - **Encoder:** Maps nodes to embeddings.\n",
    "  - **Decoder:** Reconstructs graph properties like adjacency.\n",
    "- **Usage:** \n",
    "  - Learns complex, nonlinear structural patterns.\n",
    "  - Embeddings can be used for clustering or visualization.\n",
    "- **Characteristics:** \n",
    "  - Captures structural similarity and proximity.\n",
    "  - Can reveal hidden structural roles.\n",
    "- **Example:** `SDNE` (Structural Deep Network Embedding)\n",
    "\n",
    "![unsupervisedLearning](../images/chap3_0_AE.png)\n",
    "\n",
    "ref:https://www.mdpi.com/2624-831X/4/3/16\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŸ¢ 3. Graph Neural Networks (GNNs)\n",
    "- **Idea:** Learn embeddings by aggregating and transforming information from neighbors in the graph.\n",
    "\n",
    "- **Spectral Methods:**\n",
    "  - Based on graph Laplacian and spectral theory.\n",
    "  - **Example:** `GCN` (Graph Convolutional Network)\n",
    "\n",
    "- **Spatial Methods:**\n",
    "  - Operate on node neighborhoods in the graph structure.\n",
    "  - **Example:** `GraphSAGE`\n",
    "- **Usage:** \n",
    "  - End-to-end learning for node/graph classification, link prediction, etc.\n",
    "  - Suitable for semi-supervised or supervised learning tasks.\n",
    "- **Characteristics:** \n",
    "  - Embeddings are dynamically updated during training.\n",
    "  - Highly expressive; captures both local and global graph structures.\n",
    "\n",
    "![unsupervisedLearning](../images/chap3_1_2.png)\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Key Insight:\n",
    "These unsupervised methods aim to capture structural and semantic patterns in the graph, enabling tasks such as clustering, link prediction, and node classification â€” **without requiring labeled data**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d3bf68-e8db-4361-8dc8-f424254f1fd0",
   "metadata": {},
   "source": [
    "\n",
    "### ðŸŽ¯ Summary\n",
    "\n",
    "| Approach           | Embedding Use        | Learns Structure | Task Coupling    |\n",
    "|--------------------|----------------------|------------------|------------------|\n",
    "| Shallow Embedding  | Input to ML models   | Basic            | No               |\n",
    "| Autoencoders       | Input or analysis    | Yes (nonlinear)  | Partially        |\n",
    "| GNNs               | End-to-end learning  | Yes (deep)       | Yes              |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a5e22f-d185-490b-8e31-8d81f9a3d311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlgBook",
   "language": "python",
   "name": "mlgbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
